{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f99a8a55",
   "metadata": {},
   "source": [
    "# Group Project / Assignment 4: Instruction finetuning a Llama-3.2 model\n",
    "**Assignment due 21 April 11:59pm**\n",
    "\n",
    "Welcome to the fourth and final assignment for 50.055 Machine Learning Operations. The third and fourth assignment together form the course group project. You will continue the work on a chatbot which can answer questions about SUTD to prospective students.\n",
    "\n",
    "\n",
    "**This assignment is a group assignment.**\n",
    "\n",
    "- Read the instructions in this notebook carefully\n",
    "- Add your solution code and answers in the appropriate places. The questions are marked as **QUESTION:**, the places where you need to add your code and text answers are marked as **ADD YOUR SOLUTION HERE**. The assignment is more open-ended than previous assignments, i.e. you have more freedom how to solve the problem and how to structure your code.\n",
    "- The completed notebook, including your added code and generated output will be your submission for the assignment.\n",
    "- The notebook should execute without errors from start to finish when you select \"Restart Kernel and Run All Cells..\". Please test this before submission.\n",
    "- Use the SUTD Education Cluster to solve and test the assignment. If you work on another environment, minimally test your work on the SUTD Education Cluster.\n",
    "\n",
    "**Rubric for assessment** \n",
    "\n",
    "Your submission will be graded using the following criteria. \n",
    "1. Code executes: your code should execute without errors. The SUTD Education cluster should be used to ensure the same execution environment.\n",
    "2. Correctness: the code should produce the correct result or the text answer should state the factual correct answer.\n",
    "3. Style: your code should be written in a way that is clean and efficient. Your text answers should be relevant, concise and easy to understand.\n",
    "4. Partial marks will be awarded for partially correct solutions.\n",
    "5. Creativity and innovation: in this assignment you have more freedom to design your solution, compared to the first assignments. You can show of your creativity and innovative mindset. \n",
    "6. There is a maximum of 310 points for this assignment.\n",
    "\n",
    "**ChatGPT policy** \n",
    "\n",
    "If you use AI tools, such as ChatGPT, to solve the assignment questions, you need to be transparent about its use and mark AI-generated content as such. In particular, you should include the following in addition to your final answer:\n",
    "- A copy or screenshot of the prompt you used\n",
    "- The name of the AI model\n",
    "- The AI generated output\n",
    "- An explanation why the answer is correct or what you had to change to arrive at the correct answer\n",
    "\n",
    "**Assignment Notes:** Please make sure to save the notebook as you go along. Submission Instructions are located at the bottom of the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae5e449",
   "metadata": {},
   "source": [
    "### Finetuning LLMs\n",
    "\n",
    "The goal of the assignment is to build a more advanced chatbot that can talk to prospective students and answer questions about SUTD.\n",
    "\n",
    "We will finetune a smaller 1B LLM on question-answer pairs which we synthetically generate. Then we will compare the finetuned and non-finetuned LLMs with and without RAG to see if we were able to improve the SUTD chatbot answer quality. \n",
    "\n",
    "We'll be leveraging `langchain`, `llama 3.2` and `Google AI STudio with Gemini 2.0`.\n",
    "\n",
    "Check out the docs:\n",
    "- [LangChain](https://docs.langchain.com/docs/)\n",
    "- [Llama 3.2](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_2/)\n",
    "- [Google AI Studio](https://aistudio.google.com/)\n",
    "\n",
    "Note: Google AI Studio provides a lot of free tokens but has certain rate limits. Write your code in a way that it can handle these limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62530070",
   "metadata": {},
   "source": [
    "# Install dependencies\n",
    "Use pip to install all required dependencies of this assignment in the cell below. Make sure to test this on the SUTD cluster as different environments have different software pre-installed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ec75011-c8ef-4c31-9766-2e3e9834684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in /opt/anaconda3/lib/python3.12/site-packages (0.8.4)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: google-api-python-client in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.167.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.39.0)\n",
      "Requirement already satisfied: protobuf in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.12/site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/lib/python3.12/site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/lib/python3.12/site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/anaconda3/lib/python3.12/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/anaconda3/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.24.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.12/site-packages (0.3.21)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.49)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.7)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (0.3.19)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain) (2.1)\n",
      "Requirement already satisfied: langchain-core in /opt/anaconda3/lib/python3.12/site-packages (0.3.49)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (0.3.19)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (8.2.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (6.0.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /opt/anaconda3/lib/python3.12/site-packages (from langchain-core) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.27.2)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (4.2.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.2)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.7)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.2.3)\n",
      "Requirement already satisfied: peft in /opt/anaconda3/lib/python3.12/site-packages (0.10.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from peft) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from peft) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from peft) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from peft) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from peft) (2.5.1)\n",
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (from peft) (4.45.2)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from peft) (4.66.5)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from peft) (0.27.2)\n",
      "Requirement already satisfied: safetensors in /opt/anaconda3/lib/python3.12/site-packages (from peft) (0.4.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/anaconda3/lib/python3.12/site-packages (from peft) (0.24.6)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2023.10.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.13.0->peft) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->peft) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/anaconda3/lib/python3.12/site-packages (from transformers->peft) (0.20.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2025.1.31)\n",
      "Collecting trl\n",
      "  Downloading trl-0.16.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting accelerate>=0.34.0 (from trl)\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from trl) (13.7.1)\n",
      "Collecting transformers>=4.46.0 (from trl)\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.0->trl) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.0->trl) (24.1)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.0->trl) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.0->trl) (6.0.1)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.0->trl) (2.5.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.0->trl) (0.24.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.0->trl) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=3.0.0->trl) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=3.0.0->trl) (3.10.5)\n",
      "Collecting huggingface-hub>=0.21.0 (from accelerate>=0.34.0->trl)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers>=4.46.0->trl) (2024.9.11)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.46.0->trl)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->trl) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->trl) (2.15.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=3.0.0->trl) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=3.0.0->trl) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=3.0.0->trl) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=3.0.0->trl) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.1.31)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.0.0->accelerate>=0.34.0->trl) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate>=0.34.0->trl) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=3.0.0->trl) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate>=0.34.0->trl) (2.1.3)\n",
      "Downloading trl-0.16.1-py3-none-any.whl (336 kB)\n",
      "Downloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: huggingface-hub, tokenizers, accelerate, transformers, datasets, trl\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface_hub 0.24.6\n",
      "    Uninstalling huggingface_hub-0.24.6:\n",
      "      Successfully uninstalled huggingface_hub-0.24.6\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.1\n",
      "    Uninstalling tokenizers-0.20.1:\n",
      "      Successfully uninstalled tokenizers-0.20.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.27.2\n",
      "    Uninstalling accelerate-0.27.2:\n",
      "      Successfully uninstalled accelerate-0.27.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.2\n",
      "    Uninstalling transformers-4.45.2:\n",
      "      Successfully uninstalled transformers-4.45.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.17.1\n",
      "    Uninstalling datasets-2.17.1:\n",
      "      Successfully uninstalled datasets-2.17.1\n",
      "Successfully installed accelerate-1.6.0 datasets-3.5.0 huggingface-hub-0.30.2 tokenizers-0.21.1 transformers-4.51.3 trl-0.16.1\n",
      "Requirement already satisfied: datasets in /opt/anaconda3/lib/python3.12/site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (0.30.2)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sentence-transformers in /opt/anaconda3/lib/python3.12/site-packages (4.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.4.0)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.12/site-packages (1.10.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (0.30.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub) (2025.1.31)\n",
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.3.19-py3-none-any.whl.metadata (46 kB)\n",
      "Collecting unsloth_zoo>=2025.3.17 (from unsloth)\n",
      "  Downloading unsloth_zoo-2025.3.17-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: torch>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (2.5.1)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.29.post3.tar.gz (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bitsandbytes (from unsloth)\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (24.1)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-0.9.19-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: transformers!=4.47.0,>=4.46.1 in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (4.51.3)\n",
      "Requirement already satisfied: datasets>=2.16.0 in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (3.5.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (4.66.5)\n",
      "Requirement already satisfied: psutil in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (0.44.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (1.26.4)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (1.6.0)\n",
      "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth)\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (0.10.0)\n",
      "Collecting protobuf<4.0.0 (from unsloth)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (from unsloth) (0.30.2)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.33.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (15.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (2.0.2)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.12/site-packages (from datasets>=2.16.0->unsloth) (3.10.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->unsloth) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers!=4.47.0,>=4.46.1->unsloth) (0.21.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (13.7.1)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2025.3.17->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (from unsloth_zoo>=2025.3.17->unsloth) (10.4.0)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scipy in /opt/anaconda3/lib/python3.12/site-packages (from bitsandbytes->unsloth) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/anaconda3/lib/python3.12/site-packages (from diffusers->unsloth) (6.11.0)\n",
      "Collecting docstring-parser>=0.15 (from tyro->unsloth)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting typeguard>=4.0.0 (from tyro->unsloth)\n",
      "  Downloading typeguard-4.4.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub->unsloth)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2025.1.31)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from importlib-metadata->diffusers->unsloth) (3.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas->datasets>=2.16.0->unsloth) (2023.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth) (0.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
      "Downloading unsloth-2025.3.19-py3-none-any.whl (192 kB)\n",
      "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "Downloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "Downloading unsloth_zoo-2025.3.17-py3-none-any.whl (127 kB)\n",
      "Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading diffusers-0.33.1-py3-none-any.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchvision-0.21.0-cp312-cp312-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.19-py3-none-any.whl (124 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading typeguard-4.4.2-py3-none-any.whl (35 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: xformers\n",
      "  Building wheel for xformers (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[189 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m /opt/anaconda3/lib/python3.12/site-packages/torch/utils/cpp_extension.py:497: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "  \u001b[31m   \u001b[0m   warnings.warn(msg.format('we could not find ninja.'))\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_deprecation_warning.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/attn_bias_utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/checkpoint.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/test.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_cpp_lib.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m copying xformers/info.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/importing.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/vararg_kernel.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/residual.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/input_projection.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_mem_eff_attention.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_indexing.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_revnet.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_swiglu.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_merge_attentions.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_tiled_matmul.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_nystrom_utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_attn_decoding.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sequence_parallel_fused.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sddmm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_sp24.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/benchmark_core.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/rmsnorm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/modpar_layers.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/swiglu_op.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/unbind.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/rope_padded.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/seqpar.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/sequence_parallel_fused_ops.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/sp24.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/common.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/differentiable_collectives.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/tiled_matmul.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/indexing.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/device_limits.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/find_slowest.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm_impl.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler_dcgm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/api.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profile_analyzer.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m copying xformers/profiler/profiler.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/profiler\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/_csr_ops.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/blocksparse_tensor.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m copying xformers/sparse/csr_tensor.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/sparse\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/fused_softmax.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attn_interface.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_blocksparse_attention.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/bert_padding.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_og.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_interface.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/_sputnik_sparse.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/core.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/fourier_mix.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/scaled_dot_product.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_mask.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/attention_patterns.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/sparsity_config.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m copying xformers/components/attention/base.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/components/attention\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_submit.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/batch_fetch_results.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_with_submitit.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_tasks.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/run_grid_search.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/model_wrapper.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m copying xformers/benchmarks/LRA/code/dataset.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/benchmarks/LRA/code\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_scaled_index_add.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/matmul_perf_model.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rope_padded_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/tiled_matmul_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/k_index_select_cat.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/_triton/rmsnorm_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/_triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash3.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/dispatch.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/attn_bias.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/common.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/torch_attention_compat.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_decoder.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/flash.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/cutlass.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/ck_splitk.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/triton_splitk.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/splitk_kernels.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/ops/fmha/_triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/ops/fmha/_triton\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/cross_entropy.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/losses/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/losses\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/patch_embed.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/layers/rotary.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/layers\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_ref.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_torch.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_prefill.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/interface_fa.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/test.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bench.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_prefill.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/utils.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/fwd_decode.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/flash_attn_triton_amd/bwd_ref.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/flash_attn_triton_amd\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/pretrained.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/generation.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/benchmark.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/utils/distributed.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/utils\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bigcode.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gptj.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/opt.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/llama.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/vit.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/btlm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/baichuan.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/bert.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/falcon.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt_neox.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/models/gpt.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/models\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/activations.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/fused_dense.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/rms_norm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/layer_norm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/embedding.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mlp.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/block.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/modules/mha.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/modules\n",
      "  \u001b[31m   \u001b[0m creating build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/cross_entropy.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/linear.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/k_activations.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/__init__.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/mlp.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/rotary.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m copying xformers/_flash_attn/ops/triton/layer_norm.py -> build/lib.macosx-11.0-arm64-cpython-312/xformers/_flash_attn/ops/triton\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'xformers._C' extension\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention/autograd\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention/cpu\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/sparse24\n",
      "  \u001b[31m   \u001b[0m creating build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/swiglu\n",
      "  \u001b[31m   \u001b[0m clang++ -fno-strict-overflow -DNDEBUG -O2 -Wall -fPIC -O2 -isystem /opt/anaconda3/include -arch arm64 -fPIC -O2 -isystem /opt/anaconda3/include -arch arm64 -I/private/var/folders/r0/tmhrhp0j3q3fy93p20g9q1_w0000gn/T/pip-install-qzbwqwz3/xformers_56d3ae845dcc470fac211be4df06a65e/xformers/csrc -I/opt/anaconda3/lib/python3.12/site-packages/torch/include -I/opt/anaconda3/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -I/opt/anaconda3/lib/python3.12/site-packages/torch/include/TH -I/opt/anaconda3/lib/python3.12/site-packages/torch/include/THC -I/opt/anaconda3/include/python3.12 -c xformers/csrc/attention/attention.cpp -o build/temp.macosx-11.0-arm64-cpython-312/xformers/csrc/attention/attention.o -O3 -std=c++17 -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_clang\\\" -DPYBIND11_STDLIB=\\\"_libcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1002\\\" -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0\n",
      "  \u001b[31m   \u001b[0m clang: error: unsupported option '-fopenmp'\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/clang++' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for xformers\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25h  Running setup.py clean for xformers\n",
      "Failed to build xformers\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting gradio\n",
      "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (0.115.11)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting gradio-client==1.8.0 (from gradio)\n",
      "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (0.30.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (3.10.16)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (2.10.6)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.11.6-py3-none-macosx_11_0_arm64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (0.46.0)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/anaconda3/lib/python3.12/site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from gradio-client==1.8.0->gradio) (2023.10.0)\n",
      "Collecting websockets<16.0,>=10.0 (from gradio-client==1.8.0->gradio)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.12/site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic<2.12,>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n",
      "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.11.6-py3-none-macosx_11_0_arm64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Installing collected packages: pydub, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, typer, safehttpx, gradio-client, gradio\n",
      "  Attempting uninstall: tomlkit\n",
      "    Found existing installation: tomlkit 0.11.1\n",
      "    Uninstalling tomlkit-0.11.1:\n",
      "      Successfully uninstalled tomlkit-0.11.1\n",
      "Successfully installed aiofiles-24.1.0 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 tomlkit-0.13.2 typer-0.15.2 websockets-15.0.1\n",
      "Requirement already satisfied: python-dotenv in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "Module langchain_community.embeddings not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/_api/module_import.py:69\u001b[0m, in \u001b[0;36mcreate_importer.<locals>.import_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(new_module)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1310\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1324\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_splitter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvectorstores\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FAISS\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Transformers and HuggingFace imports\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/embeddings/huggingface.py:28\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     27\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Look up attributes dynamically.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _import_attribute(name)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/langchain/_api/module_import.py:72\u001b[0m, in \u001b[0;36mcreate_importer.<locals>.import_by_name\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m new_module\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlangchain_community\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 72\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_module\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install langchain-community to access this module. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can install it using `pip install -U langchain-community`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: Module langchain_community.embeddings not found. Please install langchain-community to access this module. You can install it using `pip install -U langchain-community`"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install google-generativeai\n",
    "!pip install transformers\n",
    "!pip install langchain\n",
    "!pip install langchain-core\n",
    "!pip install peft\n",
    "!pip install trl\n",
    "!pip install datasets\n",
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n",
    "!pip install huggingface_hub\n",
    "!pip install unsloth  # Efficient fine-tuning library\n",
    "!pip install gradio    # For the UI (bonus question)\n",
    "!pip install python-dotenv  # For environment variables\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional, ClassVar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Google AI imports\n",
    "import google.generativeai as genai\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# LangChain imports\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.schema import LLMResult\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Transformers and HuggingFace imports\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from datasets import Dataset\n",
    "from huggingface_hub import login, HfApi\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563304ec",
   "metadata": {},
   "source": [
    "# Generate training data\n",
    "The first step of the assignment is generating synthetic question-answer pairs which can be used for finetuning an LLM model. \n",
    "Use the Google AI studio with the Gemini models to create -high-quality QA training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fe166d-5ef6-4da9-995e-54afffc683c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "[\n",
      "  {\n",
      "    \"name\": \"Apple\",\n",
      "    \"color\": \"Red\",\n",
      "    \"taste\": \"Sweet and crisp\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Banana\",\n",
      "    \"color\": \"Yellow\",\n",
      "    \"taste\": \"Sweet and creamy\"\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Strawberry\",\n",
      "    \"color\": \"Red\",\n",
      "    \"taste\": \"Sweet and slightly tart\"\n",
      "  }\n",
      "]\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Use langchain and the Google AI Studio APIs and a model from the Gemini 2.0 family\n",
    "# to create a text-generation chain that can produce and parse JSON output.\n",
    "# Test it by having the LLM generate a JSON array of 3 fruits\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
    "from typing import Optional, List, ClassVar\n",
    "import google.generativeai as genai\n",
    "from langchain.schema import LLMResult\n",
    "from langchain.llms.base import LLM\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()  # Loads variables from .env\n",
    "\n",
    "\n",
    "# Load API key\n",
    "GOOGLE_API_KEY = \"GOOGLE_GEMINI_API_KEY\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Custom Gemini LLM wrapper\n",
    "class GeminiLLM(LLM):\n",
    "    model_name: ClassVar[str] = \"gemini-2.0-flash\"  # Using the latest available Gemini model\n",
    "    temperature: float = 0.7\n",
    "\n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        model = genai.GenerativeModel(self.model_name)\n",
    "        response = model.generate_content(prompt)\n",
    "        return response.text\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"gemini\"\n",
    "\n",
    "# LangChain setup\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Define prompt with input variable\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"{question}\"\n",
    ")\n",
    "\n",
    "# Instantiate the chain\n",
    "llm = GeminiLLM()\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Test the chain\n",
    "response = chain.run(question=\"Generate a JSON array of 3 fruits\")\n",
    "print(response)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8edaed2",
   "metadata": {},
   "source": [
    "## Generate topics\n",
    "When generating data, it is often helpful to guide the generation process through some hierachical structure. \n",
    "Before we create question-answer pairs, let's generate some topics which the questions should be about.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45ee57ba-d3e2-45bd-9bc6-c7eeb354b926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 20 topics:\n",
      "1. SUTD Curriculum Structure\n",
      "2. Design-Centric Learning\n",
      "3. Faculty Expertise and Research\n",
      "4. Industry Connections and Internships\n",
      "5. Career Opportunities After Graduation\n",
      "6. Student Clubs and Organizations\n",
      "7. Living in Singapore\n",
      "8. Accommodation Options\n",
      "9. Tuition Fees and Financial Aid\n",
      "10. Admission Requirements and Process\n",
      "11. Scholarship Opportunities\n",
      "12. Capstone Projects and Innovation\n",
      "13. Global Opportunities and Exchange Programs\n",
      "14. SUTD's Unique Culture\n",
      "15. Student Support Services\n",
      "16. Sustainability Initiatives\n",
      "17. Technology Focus and Resources\n",
      "18. Alumni Network\n",
      "19. Entrepreneurship Programs\n",
      "20. Healthcare and Safety on Campus\n",
      "['Design-centric Curriculum', 'Global Opportunities', 'Student Life & Culture']\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Create a function 'generate_topics' which generates topics which prospective students might care about.\n",
    "#\n",
    "# Generate a list of 20 topics \n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
    "def generate_topics(num_topics):\n",
    "    \"\"\"Generate topics that prospective students might care about.\"\"\"\n",
    "    prompt = f\"\"\"Generate a list of {num_topics} topics that prospective students considering SUTD (Singapore University of Technology and Design) \n",
    "    might be interested in. Format each topic as a simple phrase separated by three commas (,,,).\n",
    "    Focus on topics relevant to university selection and student life.\n",
    "    Only provide the list of topics, no additional text.\"\"\"\n",
    "    \n",
    "    output = chain.run(question=prompt)\n",
    "    \n",
    "    # Process the output\n",
    "    topics = output.split(\",,,\")\n",
    "    topics = [topic.strip() for topic in topics if topic.strip()]\n",
    "    \n",
    "    # Ensure we have the requested number of topics\n",
    "    if len(topics) < num_topics:\n",
    "        # Generate more if needed\n",
    "        more_topics = generate_topics(num_topics - len(topics))\n",
    "        topics.extend(more_topics)\n",
    "    \n",
    "    return topics[:num_topics]  # Limit to requested number\n",
    "\n",
    "# Generate 20 topics and save them\n",
    "topics = generate_topics(20)\n",
    "print(f\"Generated {len(topics)} topics:\")\n",
    "for i, topic in enumerate(topics, 1):\n",
    "    print(f\"{i}. {topic}\")\n",
    "\n",
    "# Save topics to a file\n",
    "with open(\"topics.txt\", \"w\") as f:\n",
    "    for topic in topics:\n",
    "        f.write(f\"{topic}\\n\")\n",
    "\n",
    "print(generate_topics(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc7efb98-7b40-4230-9eda-f344b4d4e4a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUTD Curriculum Overview', 'Admission Requirements', 'Financial Aid Options', 'Student Housing', 'Career Prospects', 'Research Opportunities', 'Faculty Profiles', 'Industry Partnerships', 'Campus Life and Activities', 'Design Thinking Approach', 'Global Opportunities', 'Living in Singapore', 'Student Support Services', 'Alumni Network', 'Entrepreneurship Programs', 'Capstone Projects', 'SUTD-MIT Collaboration', 'Sustainability Initiatives', 'Technology Focus', 'Student Clubs and Organizations']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Generate a list of 20 topics \n",
    "# We save a copy to disk and reload it from there if the file exists\n",
    "\n",
    "output = generate_topics(20)\n",
    "print(output)\n",
    "\n",
    "with open(\"topics.txt\", \"w\") as f:\n",
    "\n",
    "    for i in output:\n",
    "        f.write(i+\"\\n\") if i != \",\" else None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48c4b4e",
   "metadata": {},
   "source": [
    "## Generate questions\n",
    "Now generate a set of questions about each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85706c9c-593d-459c-b86e-4011500cff05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample questions about Academic Programs:\n",
      "1. What opportunities are there to specialize or tailor the curriculum within the Architecture and Sustainable Design pillar beyond the required core courses, specifically in areas like urban planning or computational design?\n",
      "2. Could you provide examples of past capstone projects undertaken by students in the Engineering Product Development pillar that have successfully transitioned into startups or commercialized products, and what resources does SUTD offer to support such entrepreneurial endeavors?\n",
      "3. How does the Humanities, Arts, and Social Sciences (HASS) curriculum integrate with the technical pillars to foster interdisciplinary thinking and communication skills, and are there opportunities to pursue independent research projects that combine HASS perspectives with technological innovations?\n",
      "Generating questions for topic: SUTD Curriculum Overview\n",
      "Generating questions for topic: Admission Requirements\n",
      "Generating questions for topic: Financial Aid Options\n",
      "Generating questions for topic: Student Housing\n",
      "Generating questions for topic: Career Prospects\n",
      "Generating questions for topic: Research Opportunities\n",
      "Generating questions for topic: Faculty Profiles\n",
      "Generating questions for topic: Industry Partnerships\n",
      "Generating questions for topic: Campus Life and Activities\n",
      "Generating questions for topic: Design Thinking Approach\n",
      "Generating questions for topic: Global Opportunities\n",
      "Generating questions for topic: Living in Singapore\n",
      "Generating questions for topic: Student Support Services\n",
      "Generating questions for topic: Alumni Network\n",
      "Generating questions for topic: Entrepreneurship Programs\n",
      "Generating questions for topic: Capstone Projects\n",
      "Generating questions for topic: SUTD-MIT Collaboration\n",
      "Generating questions for topic: Sustainability Initiatives\n",
      "Generating questions for topic: Technology Focus\n",
      "Generating questions for topic: Student Clubs and Organizations\n"
     ]
    }
   ],
   "source": [
    "# QUESTION: Create a function 'generate_questions' which generates quetions about a given topic. \n",
    "# Generate a list of 10 questions per topics. In total you should have 200 questions. \n",
    "#\n",
    "\n",
    "def generate_questions(topic, num_questions=10):\n",
    "    \"\"\"Generate a list of questions about a specific topic that prospective students might ask.\"\"\"\n",
    "    prompt = f\"\"\"Generate {num_questions} specific questions that prospective students might ask about \"{topic}\" \n",
    "    when considering SUTD (Singapore University of Technology and Design).\n",
    "    Format each question separated by three commas (,,,).\n",
    "    Make the questions diverse, specific, and realistic.\n",
    "    Only provide the list of questions, no additional text.\"\"\"\n",
    "    \n",
    "    output = chain.run(question=prompt)\n",
    "    \n",
    "    # Process the output\n",
    "    questions = output.split(\",,,\")\n",
    "    questions = [q.strip() for q in questions if q.strip()]\n",
    "    \n",
    "    # Ensure we have the requested number of questions\n",
    "    if len(questions) < num_questions:\n",
    "        # Generate more if needed\n",
    "        more_questions = generate_questions(topic, num_questions - len(questions))\n",
    "        questions.extend(more_questions)\n",
    "    \n",
    "    return questions[:num_questions]  # Limit to requested number\n",
    "\n",
    "# Test with a sample topic\n",
    "sample_questions = generate_questions(\"Academic Programs\", 3)\n",
    "print(f\"Sample questions about Academic Programs:\")\n",
    "for i, question in enumerate(sample_questions, 1):\n",
    "    print(f\"{i}. {question}\")\n",
    "\n",
    "# Generate questions for all topics and save to CSV\n",
    "with open(\"topics.txt\", \"r\") as f_topics, open(\"questions.csv\", \"w\", newline='') as f_csv:\n",
    "    writer = csv.writer(f_csv)\n",
    "    writer.writerow([\"Topic\", \"Question\"])  # Header row\n",
    "    \n",
    "    for topic in f_topics:\n",
    "        topic = topic.strip()\n",
    "        if not topic:\n",
    "            continue\n",
    "            \n",
    "        print(f\"Generating questions for topic: {topic}\")\n",
    "        questions = generate_questions(topic, 10)\n",
    "        \n",
    "        for question in questions:\n",
    "            writer.writerow([topic, question])\n",
    "        \n",
    "        # Add a delay to avoid rate limits\n",
    "        time.sleep(3)\n",
    "       \n",
    " \n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (20 points)---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "1b3c9080-c3d0-458e-8c25-fa869fe0ae37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"How does the program's curriculum reflect current industry trends and research?\", \"What is the faculty's research output and its impact on the field?\", 'What are the career placement rates and average starting salaries for graduates of this program?']\n"
     ]
    }
   ],
   "source": [
    "# test it\n",
    "print(generate_questions(\"Academic Reputation and Program Quality\", 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "879af438-7482-4b66-ba7a-a888e554df5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic Programs\n",
      "How does the university track and measure the success of its alumni network in supporting student outcomes?\n",
      "Faculty Expertise\n",
      "What are the program's learning outcomes and how are they assessed?\n",
      "Research Opportunities\n",
      "What are the faculty's areas of expertise and how do they align with my academic interests?\n",
      "Campus Life\n",
      "What are the potential career benefits of participating in undergraduate research (e.g., improved job prospects, graduate school admission)?\n",
      "Student Housing\n",
      ",What kind of recreational facilities are available on campus (e.g., gym, swimming pool, sports fields) and what intramural sports or fitness programs are offered?\n",
      "Financial Aid & Scholarships\n",
      "What is the process for moving in and out of student housing?\n",
      "Tuition & Fees\n",
      "Who can I contact if I have questions about my financial aid application or award?\n",
      "Career Services\n",
      "What resources are available to help me create a budget and manage my finances as a student?\n",
      "Internship Opportunities\n",
      "How early in my academic career can I begin utilizing career services, and are services available to alumni?\n",
      "Study Abroad Programs\n",
      "How can I apply for an internship, and what is the application deadline?,\n",
      "Location & Surroundings\n",
      "What is the level of language proficiency required and are there language courses available?\n",
      "Student Clubs & Organizations\n",
      ",How does the university interact with and contribute to the local community?\n",
      "Diversity & Inclusion\n",
      "What events and activities do clubs typically organize?\n",
      "Health & Wellness Resources\n",
      "How does the university engage with the local community to promote diversity and inclusion?\n",
      "Safety & Security\n",
      "What is the university's policy on vaccinations and required health screenings?\n",
      "Alumni Network\n",
      "Are there safe escort programs available for students walking alone at night?\n",
      "Technology & Facilities\n",
      "Can I easily connect with alumni working in my specific field of interest?\n",
      "Admission Requirements\n",
      "What is the university's commitment to sustainable practices, such as energy efficiency and waste reduction, in its facilities and technology usage?\n",
      "Application Process\n",
      "What is the acceptance rate for my program of interest, and what are my chances of being admitted based on my academic profile?\n",
      "Campus Visit Options\n",
      "Whom should I contact if I have questions about the application process or encounter technical difficulties?\n"
     ]
    }
   ],
   "source": [
    "# # QUESTION: Now let's put it together and generate 10 questions for each topic. Save the questions in a local file.\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (20 points)---\n",
    "import csv\n",
    "import time\n",
    "\n",
    "with open(\"topics.txt\", \"r\") as f_topics, open(\"questions.csv\", \"w\", newline='') as f_csv:\n",
    "    writer = csv.writer(f_csv)\n",
    "    \n",
    "    for topic in f_topics:\n",
    "        topic = topic.strip()\n",
    "        print(topic)\n",
    "        print(question)\n",
    "        questions = generate_questions(topic, 10)\n",
    "        time.sleep(4)\n",
    "\n",
    "        for question in questions:\n",
    "            row = [topic, question]  \n",
    "            writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35dd1d4",
   "metadata": {},
   "source": [
    "## Generate Answers\n",
    "\n",
    "Now create answers for the questions. \n",
    "\n",
    "You can use the Google AI Studio Gemini model (assuming that they are good enough to generate good answers), your RAG system from assignment 3 or any other method you choose to generate answers for your question dataset.\n",
    "\n",
    "Note: it is normal that some LLM calls fail, even with retry, so maybe you end up with less than 200 QA pairs but it should be at least 160 QA pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e785dd-ab6f-41f8-961b-bf6f9ae24a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample answer:\n",
      "SUTD offers a focused range of undergraduate and postgraduate programs designed to integrate technology and design thinking. Here's a breakdown:\n",
      "\n",
      "**Undergraduate Programs (Bachelor of Engineering or Bachelor of Science):**\n",
      "\n",
      "*   **Architecture and Sustainable Design (ASD):** This program focuses on architectural design, urban planning, and sustainability, emphasizing innovative solutions for the built environment. Students earn a Bachelor of Science (Architecture and Sustainable Design) degree.\n",
      "\n",
      "*   **Engineering Product Development (EPD):** This program emphasizes the entire product development lifecycle, from ideation to manufacturing, covering aspects like mechanical engineering, electrical engineering, and design. Students earn a Bachelor of Engineering (Engineering Product Development) degree.\n",
      "\n",
      "*   **Engineering Systems and Design (ESD):** This program focuses on the design and optimization of complex systems, encompassing areas like data analytics, operations research, and supply chain management. Students earn a Bachelor of Engineering (Engineering Systems and Design) degree.\n",
      "\n",
      "*   **Information Systems Technology and Design (ISTD):** This program focuses on the intersection of information technology, software engineering, and design, covering topics like cybersecurity, artificial intelligence, and software development. Students earn a Bachelor of Engineering (Information Systems Technology and Design) degree.\n",
      "\n",
      "*   **Design and Artificial Intelligence (DAI):** A newer program (introduced in AY2021), DAI merges design thinking with AI. Students will gain skills in both areas to create innovative solutions leveraging the power of artificial intelligence. Students earn a Bachelor of Engineering (Design and Artificial Intelligence) degree.\n",
      "\n",
      "**Key features of SUTD's undergraduate programs:**\n",
      "\n",
      "*   **Common Curriculum in the First Three Terms:** All students take a common curriculum in their first three terms, providing a foundation in mathematics, science, design, and humanities, arts, and social sciences (HASS). This allows students to explore different disciplines before specializing in their chosen program.\n",
      "*   **Design-Centric Learning:** A strong emphasis on design thinking and hands-on projects.\n",
      "*   **Interdisciplinary Approach:** Encourages collaboration and learning across different disciplines.\n",
      "*   **Flexibility in Specialization:** While you select a primary pillar (ASD, EPD, ESD, ISTD, DAI), you can explore related fields through electives and capstone projects.\n",
      "\n",
      "**Postgraduate Programs:**\n",
      "\n",
      "*   **Master of Science (MSc) and Doctor of Philosophy (PhD) Programs:** These are research-focused programs offered in various areas aligned with SUTD's pillars (Architecture and Sustainable Design, Engineering Product Development, Engineering Systems and Design, and Information Systems Technology and Design, and AI). They also have specific specializations within each pillar.\n",
      "*   **SUTD-MIT Joint Programs:** SUTD has collaborations with MIT offering joint master's and PhD programs, often involving research stays at MIT. Examples include the SUTD-MIT International Design Centre (IDC). Look for options related to design, technology and management.\n",
      "*   **Executive Education:** SUTD also offers executive education programs and short courses for working professionals to upskill and reskill in relevant areas.\n",
      "\n",
      "**In Summary:**\n",
      "\n",
      "SUTD's academic programs are designed to equip students with the technical skills, design thinking abilities, and interdisciplinary perspectives needed to address complex challenges in a rapidly evolving world. The curriculum emphasizes innovation, collaboration, and a hands-on approach to learning. Potential students should carefully consider their interests and career goals when choosing a specific program. The SUTD website is the best resource for the most up-to-date details on curriculum and admission requirements.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151b1e703f744de887682fc744d85106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating answers: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m                 writer\u001b[38;5;241m.\u001b[39mwriterow([topic, question, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError generating answer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     63\u001b[0m             \u001b[38;5;66;03m# Add a delay to avoid rate limits\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m             time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnicode error encountered. Trying a different approach...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# QUESTION: Generate answers to al your questions using Gemini, your SUTD RAG system or any other method.\n",
    "# Split your dataset in to 80% training and 20% test dataset.\n",
    "# Store all questions and answer pairs in a huggingface dataset `sutd_qa_dataset` and push it to your Huggingface hub. \n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "\n",
    "def generate_answer(question, topic=None):\n",
    "    \"\"\"Generate an answer to a specific question about SUTD.\"\"\"\n",
    "    context = f\" regarding {topic}\" if topic else \"\"\n",
    "    \n",
    "    prompt = f\"\"\"You are an expert on Singapore University of Technology and Design (SUTD).\n",
    "    Please answer the following question{context} with accurate information about SUTD.\n",
    "    Provide a comprehensive but concise answer that a prospective student would find helpful.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Answer:\"\"\"\n",
    "    \n",
    "    output = chain.run(question=prompt)\n",
    "    return output.strip()\n",
    "\n",
    "# Test with a sample question\n",
    "sample_answer = generate_answer(\"What programs does SUTD offer?\", \"Academic Programs\")\n",
    "print(f\"Sample answer:\\n{sample_answer}\")\n",
    "\n",
    "# Generate answers for all questions and save to CSV\n",
    "# First, try to read the questions file with a more flexible encoding\n",
    "try:\n",
    "    # Try reading with latin1 encoding (which can handle any byte value)\n",
    "    with open(\"questions.csv\", \"r\", encoding=\"latin1\") as f_csv_in, open(\"qa_dataset.csv\", \"w\", newline='', encoding=\"utf-8\") as f_csv_out:\n",
    "        reader = csv.reader(f_csv_in)\n",
    "        writer = csv.writer(f_csv_out)\n",
    "        writer.writerow([\"Topic\", \"Question\", \"Answer\"])  # Header row\n",
    "        \n",
    "        # Skip header if it exists\n",
    "        try:\n",
    "            header = next(reader)\n",
    "            if header and \"Topic\" in header[0]:\n",
    "                pass  # This was a header row\n",
    "            else:\n",
    "                # It wasn't a header, write it as data\n",
    "                if len(header) >= 2:\n",
    "                    topic, question = header[0], header[1]\n",
    "                    writer.writerow([topic, question, generate_answer(question, topic)])\n",
    "        except StopIteration:\n",
    "            print(\"Empty file\")\n",
    "        \n",
    "        for row in tqdm(reader, desc=\"Generating answers\"):\n",
    "            if not row or len(row) < 2:\n",
    "                continue  # Skip empty rows\n",
    "                \n",
    "            topic, question = row\n",
    "            \n",
    "            try:\n",
    "                answer = generate_answer(question, topic)\n",
    "                # Clean the answer to ensure it contains only valid characters\n",
    "                answer = ''.join(char if ord(char) < 128 else ' ' for char in answer)\n",
    "                writer.writerow([topic, question, answer])\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating answer for '{question}': {e}\")\n",
    "                writer.writerow([topic, question, \"Error generating answer\"])\n",
    "            \n",
    "            # Add a delay to avoid rate limits\n",
    "            time.sleep(3)\n",
    "            \n",
    "except UnicodeDecodeError:\n",
    "    print(\"Unicode error encountered. Trying a different approach...\")\n",
    "    \n",
    "    # If that fails, read the file as binary and manually handle encoding\n",
    "    with open(\"questions.csv\", \"rb\") as f_binary:\n",
    "        content = f_binary.read()\n",
    "        \n",
    "        # Try different encodings\n",
    "        encodings_to_try = [\"utf-8\", \"latin1\", \"cp1252\", \"iso-8859-1\"]\n",
    "        decoded_content = None\n",
    "        \n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                decoded_content = content.decode(encoding, errors=\"replace\")\n",
    "                print(f\"Successfully decoded with {encoding}\")\n",
    "                break\n",
    "            except UnicodeDecodeError:\n",
    "                continue\n",
    "        \n",
    "        if decoded_content is None:\n",
    "            print(\"Could not decode the file with any encoding\")\n",
    "            # As a last resort, force decode with replacement\n",
    "            decoded_content = content.decode(\"utf-8\", errors=\"replace\")\n",
    "        \n",
    "        # Parse the CSV manually\n",
    "        lines = decoded_content.split(\"\\n\")\n",
    "        with open(\"qa_dataset.csv\", \"w\", newline='', encoding=\"utf-8\") as f_csv_out:\n",
    "            writer = csv.writer(f_csv_out)\n",
    "            writer.writerow([\"Topic\", \"Question\", \"Answer\"])  # Header row\n",
    "            \n",
    "            for i, line in enumerate(lines):\n",
    "                # Skip header\n",
    "                if i == 0 and \"Topic\" in line:\n",
    "                    continue\n",
    "                    \n",
    "                parts = line.split(\",\")\n",
    "                if len(parts) >= 2:\n",
    "                    topic = parts[0].strip()\n",
    "                    # Handle cases where the question itself might contain commas\n",
    "                    question = \",\".join(parts[1:]).strip()\n",
    "                    \n",
    "                    if question:\n",
    "                        try:\n",
    "                            answer = generate_answer(question, topic)\n",
    "                            # Clean the answer to ensure it contains only valid characters\n",
    "                            answer = ''.join(char if ord(char) < 128 else ' ' for char in answer)\n",
    "                            writer.writerow([topic, question, answer])\n",
    "                            \n",
    "                            # Add a delay to avoid rate limits\n",
    "                            time.sleep(1)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error generating answer for '{question}': {e}\")\n",
    "                            writer.writerow([topic, question, \"Error generating answer\"])\n",
    "\n",
    "\n",
    "\n",
    "## Interrupted; generation was done on seerate machine\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16a0546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 200 question-answer pairs\n",
      "Training dataset: 160 pairs\n",
      "Test dataset: 40 pairs\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test datasets (80/20 split)\n",
    "# qa_data = pd.read_csv(\"qa_dataset.csv\", encoding=\"utf-8\")\n",
    "# If the above still fails, try this alternative:\n",
    "qa_data = pd.read_csv(\"qa_dataset.csv\", encoding=\"latin1\")\n",
    "\n",
    "train_data = qa_data.sample(frac=0.8, random_state=42)\n",
    "test_data = qa_data.drop(train_data.index)\n",
    "\n",
    "train_data.to_csv(\"qa_train_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "test_data.to_csv(\"qa_test_dataset.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Generated {len(qa_data)} question-answer pairs\")\n",
    "print(f\"Training dataset: {len(train_data)} pairs\")\n",
    "print(f\"Test dataset: {len(test_data)} pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26209b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Response:\n",
      "The Singapore University of Technology and Design (SUTD) was founded in **2009**.\n"
     ]
    }
   ],
   "source": [
    "# test the chain\n",
    "question = \"When was SUTD founded?\"\n",
    "\n",
    "# Now run the answer generation chain\n",
    "response = generate_answer(question)\n",
    "print(\"\\nModel Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "80228b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic Programs\n",
      "\"What are the specific admission requirements for this program?\"\n",
      "Academic Programs\n",
      "\"What is the program's curriculum structure and what courses are required?\"\n",
      "Academic Programs\n",
      "\"Are there opportunities for internships, research, or study abroad within this program?\"\n",
      "Academic Programs\n",
      "\"What are the career prospects and typical job titles for graduates of this program?\"\n",
      "Academic Programs\n",
      "\"What is the average class size and what is the student-to-faculty ratio?\"\n",
      "Academic Programs\n",
      "\"What resources and support services are available to students in this program (e.g., tutoring, advising, career counseling)?\"\n",
      "Academic Programs\n",
      "\"Are there any opportunities for specialization or concentration within this program?\"\n",
      "Academic Programs\n",
      "\"How does this program incorporate practical experience or real-world application of the concepts taught?\"\n",
      "Academic Programs\n",
      "\"What is the program's accreditation status and how does that benefit students?\"\n",
      "Academic Programs\n",
      "\"What are the program's learning outcomes and how are they assessed?\"\n",
      "Faculty Expertise\n",
      "\"What percentage of faculty hold terminal degrees in their field?\"\n",
      "Faculty Expertise\n",
      "\"What is the average class size taught by professors versus teaching assistants?\"\n",
      "Faculty Expertise\n",
      "\"What opportunities are there to work directly with faculty on research projects?\"\n",
      "Faculty Expertise\n",
      "\"How accessible are faculty outside of class time for questions and mentorship?\"\n",
      "Faculty Expertise\n",
      "\"What are the primary research areas and publications of the faculty in this department?\"\n",
      "Faculty Expertise\n",
      "\"Do faculty have industry experience or collaborations that connect the curriculum to real-world applications?\"\n",
      "Faculty Expertise\n",
      "\"How many faculty are actively involved in professional development and staying current in their fields?\"\n",
      "Faculty Expertise\n",
      "\"What is the faculty-to-student ratio in this program?\"\n",
      "Faculty Expertise\n",
      "\"Are there visiting faculty or guest lecturers that contribute to the program's expertise?\"\n",
      "Faculty Expertise\n",
      "\"What are the faculty's areas of expertise and how do they align with my academic interests?\"\n",
      "Research Opportunities\n",
      "\"What research opportunities are available for undergraduate students in my major?\"\n",
      "Research Opportunities\n",
      "\"Are there research opportunities for students with my specific interests within the department?\"\n",
      "Research Opportunities\n",
      "\"How do I find and contact faculty members who are conducting research I'm interested in?\"\n",
      "Research Opportunities\n",
      "\"Are there specific programs or funding opportunities (e.g., grants, stipends) to support undergraduate research?\"\n",
      "Research Opportunities\n",
      "\"What is the typical time commitment required for undergraduate research projects?\"\n",
      "Research Opportunities\n",
      "\"Can undergraduate research be used to fulfill course requirements or earn academic credit?\"\n",
      "Research Opportunities\n",
      "\"Are there opportunities to present or publish research findings at conferences or in journals?\"\n",
      "Research Opportunities\n",
      "\"What kind of training or mentorship is provided to undergraduate researchers?\"\n",
      "Research Opportunities\n",
      "\"What are the eligibility requirements for participating in research (e.g., GPA, specific coursework)?\"\n",
      "Research Opportunities\n",
      "\"What are the potential career benefits of participating in undergraduate research (e.g., improved job prospects, graduate school admission)?\"\n",
      "Campus Life\n",
      "\"What types of clubs and organizations are available on campus and how easy is it to start a new one?\"\n",
      "Campus Life\n",
      "\",What is the campus housing like, including options for different living styles (e.g., single rooms, suites, apartments)?\"\n",
      "Campus Life\n",
      "\"What is the food like in the dining halls and are there other food options available on campus (e.g., cafes, restaurants)?\"\n",
      "Campus Life\n",
      "\"What kind of support services are available for students, such as academic advising, counseling, and career services?\"\n",
      "Campus Life\n",
      "\",What is the social scene like on campus and are there many opportunities for students to connect with each other?\"\n",
      "Campus Life\n",
      "\",How safe is the campus and what security measures are in place?\"\n",
      "Campus Life\n",
      "\",What is the surrounding town or city like, and what opportunities are there for students to explore and engage with the local community?\"\n",
      "Campus Life\n",
      "\",What is the student body like in terms of diversity (e.g., race, ethnicity, socioeconomic background, interests)?\"\n",
      "Campus Life\n",
      "\"What opportunities are there for students to get involved in campus governance and decision-making?\"\n",
      "Campus Life\n",
      "\",What kind of recreational facilities are available on campus (e.g., gym, swimming pool, sports fields) and what intramural sports or fitness programs are offered?\"\n",
      "Student Housing\n",
      "\"What types of housing are available (e.g., dorms, apartments, suites)?\"\n",
      "Student Housing\n",
      "\"What is the cost of housing and what payment options are offered?\"\n",
      "Student Housing\n",
      "\"What is included in the housing fee (e.g., utilities, internet, laundry)?\"\n",
      "Student Housing\n",
      "\"What is the process for applying for housing and what are the deadlines?\"\n",
      "Student Housing\n",
      "\"What are the roommate matching options and how are roommates assigned?\"\n",
      "Student Housing\n",
      "\"What are the rules and regulations for student housing?\"\n",
      "Student Housing\n",
      "\"What are the security measures in place in student housing?\"\n",
      "Student Housing\n",
      "\"What amenities are available in student housing (e.g., common areas, gyms, study rooms)?\"\n",
      "Student Housing\n",
      "\"What is the proximity of student housing to campus buildings, classes, and other facilities?\"\n",
      "Student Housing\n",
      "\"What is the process for moving in and out of student housing?\"\n",
      "Financial Aid & Scholarships\n",
      "\"What types of financial aid are available, including grants, scholarships, loans, and work-study programs?\"\n",
      "Financial Aid & Scholarships\n",
      "\"What is the deadline to apply for financial aid and scholarships, and what documents are required?\"\n",
      "Financial Aid & Scholarships\n",
      "\"How does my family's income and assets affect my eligibility for financial aid?\"\n",
      "Financial Aid & Scholarships\n",
      "\"Are there scholarships specifically for students with my major, background, or interests?\"\n",
      "Financial Aid & Scholarships\n",
      "\"What is the average financial aid package awarded to students at this institution?\"\n",
      "Financial Aid & Scholarships\n",
      "\"Does the financial aid package cover the full cost of attendance, including tuition, fees, room and board, and books?\"\n",
      "Financial Aid & Scholarships\n",
      "\"Are scholarships renewable, and what are the requirements for maintaining them?\"\n",
      "Financial Aid & Scholarships\n",
      "\"What happens to my financial aid if I take a semester off or study abroad?\"\n",
      "Financial Aid & Scholarships\n",
      "\"What are the interest rates and repayment terms for student loans?\"\n",
      "Financial Aid & Scholarships\n",
      "\"Who can I contact if I have questions about my financial aid application or award?\"\n",
      "Tuition & Fees\n",
      "\"What is the total cost of tuition and mandatory fees per semester/year for my specific program of study?\"\n",
      "Tuition & Fees\n",
      "\"What payment options are available for tuition and fees, and what are the deadlines for each payment?\"\n",
      "Tuition & Fees\n",
      "\"Are there any additional fees beyond tuition and mandatory fees, such as lab fees, technology fees, or activity fees?\"\n",
      "Tuition & Fees\n",
      "\"Is there a tuition difference for in-state vs. out-of-state students, and what are the requirements for establishing residency?\"\n",
      "Tuition & Fees\n",
      "\"What financial aid options are available, including scholarships, grants, and loans, and what is the application process?\"\n",
      "Tuition & Fees\n",
      "\"Does the university offer tuition waivers or discounts for certain student populations, such as veterans or children of alumni?\"\n",
      "Tuition & Fees\n",
      "\"What is the refund policy if I withdraw from a course or from the university altogether?\"\n",
      "Tuition & Fees\n",
      "\"Are tuition and fees subject to change, and if so, how often and by how much?\"\n",
      "Tuition & Fees\n",
      "\"Are there any work-study opportunities available to help offset the cost of tuition and fees?\"\n",
      "Tuition & Fees\n",
      "\"What resources are available to help me create a budget and manage my finances as a student?\"\n",
      "Career Services\n",
      "\"What types of career counseling and advising services are offered to students?\"\n",
      "Career Services\n",
      "\"What resources are available to help students explore different career paths and industries?\"\n",
      "Career Services\n",
      "\"Does the career services office offer resume and cover letter workshops or individual critiques?\"\n",
      "Career Services\n",
      "\"Are there opportunities for mock interviews, and how are they conducted (e.g., with alumni, employers)?\"\n",
      "Career Services\n",
      "\"What is the career services office's relationship with employers in the fields I'm interested in?\"\n",
      "Career Services\n",
      "\"Does the university have a strong alumni network, and how does the career services office leverage it to connect students with alumni working in relevant fields?\"\n",
      "Career Services\n",
      "\"What kind of internship or co-op opportunities are available, and how does the career services office help students find and secure them?\"\n",
      "Career Services\n",
      "\"What career fairs or recruiting events does the university host, and what types of companies typically attend?\"\n",
      "Career Services\n",
      "\"What data does the career services office collect and share about graduate employment rates, average salaries, and job placement locations for different majors?\"\n",
      "Career Services\n",
      "\"How early in my academic career can I begin utilizing career services, and are services available to alumni?\"\n",
      "Internship Opportunities\n",
      "\"What types of internship opportunities are available, and in which departments or areas?,\"\n",
      "Internship Opportunities\n",
      "\"What are the typical responsibilities and day-to-day tasks of an intern?,\"\n",
      "Internship Opportunities\n",
      "\"What are the qualifications and requirements for applying to an internship (e.g., GPA, major, skills)?,\"\n",
      "Internship Opportunities\n",
      "\"What is the duration and timeframe of the internship program (e.g., summer, semester, year-round)?,\"\n",
      "Internship Opportunities\n",
      "\"Is the internship paid or unpaid, and if paid, what is the hourly rate or stipend?,\"\n",
      "Internship Opportunities\n",
      "\"What kind of training, mentorship, or support is provided to interns during the program?,\"\n",
      "Internship Opportunities\n",
      "\"Does the internship program offer opportunities for professional development, networking, or skill enhancement?,\"\n",
      "Internship Opportunities\n",
      "\"Does the company offer opportunities for full-time employment after the internship program?,\"\n",
      "Internship Opportunities\n",
      "\"What is the company culture like, and how does it support interns' learning and growth?,\"\n",
      "Internship Opportunities\n",
      "\"How can I apply for an internship, and what is the application deadline?,\"\n",
      "Study Abroad Programs\n",
      "\"What are the academic requirements and course transfer policies?\"\n",
      "Study Abroad Programs\n",
      "\"What is the total cost of the program, including tuition, fees, housing, and living expenses?\"\n",
      "Study Abroad Programs\n",
      "\"What scholarships or financial aid options are available for study abroad?\"\n",
      "Study Abroad Programs\n",
      "\"What types of support services are offered, such as health insurance, visa assistance, and emergency support?\"\n",
      "Study Abroad Programs\n",
      "\"What are the housing options and what is the living situation like in the host country?\"\n",
      "Study Abroad Programs\n",
      "\"What cultural activities and excursions are included in the program?\"\n",
      "Study Abroad Programs\n",
      "\"What are the safety and security measures in place and what is the risk management plan?\"\n",
      "Study Abroad Programs\n",
      "\"How will studying abroad benefit my academic and professional goals?\"\n",
      "Study Abroad Programs\n",
      "\"What is the application process and what are the deadlines?\"\n",
      "Study Abroad Programs\n",
      "\"What is the level of language proficiency required and are there language courses available?\"\n",
      "Location & Surroundings\n",
      "\"How safe is the surrounding neighborhood, both during the day and at night?\"\n",
      "Location & Surroundings\n",
      "\",What is the cost of living like in the area, including rent, groceries, and transportation?\"\n",
      "Location & Surroundings\n",
      "\",Are there convenient public transportation options to get to campus and other parts of the city?\"\n",
      "Location & Surroundings\n",
      "\",What types of amenities are available nearby, such as grocery stores, restaurants, parks, and entertainment venues?\"\n",
      "Location & Surroundings\n",
      "\",What is the overall atmosphere and vibe of the neighborhood surrounding the university?\"\n",
      "Location & Surroundings\n",
      "\",Are there opportunities for outdoor recreation and activities in the area?\"\n",
      "Location & Surroundings\n",
      "\",How easy is it to access healthcare facilities and emergency services?\"\n",
      "Location & Surroundings\n",
      "\",Is there a strong sense of community in the surrounding area, and are there opportunities to get involved?\"\n",
      "Location & Surroundings\n",
      "\",What is the distance to major attractions, cultural landmarks, and transportation hubs like airports and train stations?\"\n",
      "Location & Surroundings\n",
      "\",How does the university interact with and contribute to the local community?\"\n",
      "Student Clubs & Organizations\n",
      "\"What clubs and organizations are most popular on campus?\"\n",
      "Student Clubs & Organizations\n",
      "\"Are there clubs related to my specific major or interests?\"\n",
      "Student Clubs & Organizations\n",
      "\"How easy is it to join a club?\"\n",
      "Student Clubs & Organizations\n",
      "\"What is the time commitment typically involved in club membership?\"\n",
      "Student Clubs & Organizations\n",
      "\"Are there opportunities for leadership positions within clubs?\"\n",
      "Student Clubs & Organizations\n",
      "\"Do clubs offer opportunities for networking and career development?\"\n",
      "Student Clubs & Organizations\n",
      "\"Are there any clubs focused on community service or activism?\"\n",
      "Student Clubs & Organizations\n",
      "\"Does the university provide funding or resources to support student clubs?\"\n",
      "Student Clubs & Organizations\n",
      "\"Are there opportunities to start a new club if my interest isn't represented?\"\n",
      "Student Clubs & Organizations\n",
      "\"What events and activities do clubs typically organize?\"\n",
      "Diversity & Inclusion\n",
      "\"What resources and support systems are available for students from underrepresented backgrounds?\"\n",
      "Diversity & Inclusion\n",
      "\"How does the university promote a diverse and inclusive campus culture both inside and outside the classroom?\"\n",
      "Diversity & Inclusion\n",
      "\"What percentage of the student body, faculty, and staff identify as members of underrepresented groups?\"\n",
      "Diversity & Inclusion\n",
      "\"Are there any student organizations or affinity groups dedicated to supporting diversity and inclusion?\"\n",
      "Diversity & Inclusion\n",
      "\"What specific initiatives or programs has the university implemented to address issues of equity and inclusion?\"\n",
      "Diversity & Inclusion\n",
      "\"How does the curriculum incorporate diverse perspectives and experiences?\"\n",
      "Diversity & Inclusion\n",
      "\"What training or workshops are available to students, faculty, and staff on topics related to diversity, equity, and inclusion?\"\n",
      "Diversity & Inclusion\n",
      "\"How does the university handle incidents of discrimination or bias?\"\n",
      "Diversity & Inclusion\n",
      "\"What is the university's commitment to accessibility for students with disabilities?\"\n",
      "Diversity & Inclusion\n",
      "\"How does the university engage with the local community to promote diversity and inclusion?\"\n",
      "Health & Wellness Resources\n",
      "\"What mental health services are available to students, and how accessible are they?\"\n",
      "Health & Wellness Resources\n",
      "\"What resources are available for students struggling with food insecurity or housing instability?\"\n",
      "Health & Wellness Resources\n",
      "\"Does the university offer health insurance options, and what are the coverage details and costs?\"\n",
      "Health & Wellness Resources\n",
      "\"What kind of disability services are offered, including academic accommodations and accessibility resources?\"\n",
      "Health & Wellness Resources\n",
      "\"What wellness programs are offered, such as stress management workshops, fitness classes, or mindfulness training?\"\n",
      "Health & Wellness Resources\n",
      "\"What resources are available for students who experience sexual assault or harassment, including reporting procedures and support services?\"\n",
      "Health & Wellness Resources\n",
      "\"Is there a health center on campus, and what types of medical services are provided?\"\n",
      "Health & Wellness Resources\n",
      "\"What support groups or peer mentoring programs are available for specific student populations, such as LGBTQ+ students or students of color?\"\n",
      "Health & Wellness Resources\n",
      "\"Are there resources to help students manage substance use or addiction?\"\n",
      "Health & Wellness Resources\n",
      "\"What is the university's policy on vaccinations and required health screenings?\"\n",
      "Safety & Security\n",
      "\"How safe is the campus at night?\"\n",
      "Safety & Security\n",
      "\"What security measures are in place in campus dorms/housing?\"\n",
      "Safety & Security\n",
      "\"What is the process for reporting a crime or safety concern?\"\n",
      "Safety & Security\n",
      "\"Does the university have its own police or security force?\"\n",
      "Safety & Security\n",
      "\"Are there emergency call boxes located around campus?\"\n",
      "Safety & Security\n",
      "\"What resources are available for students who experience harassment or assault?\"\n",
      "Safety & Security\n",
      "\"What is the university's policy on campus safety alerts and emergency notifications?\"\n",
      "Safety & Security\n",
      "\"How does the university address cybersecurity threats and protect student data?\"\n",
      "Safety & Security\n",
      "\"What training or education programs are offered on personal safety and crime prevention?\"\n",
      "Safety & Security\n",
      "\"Are there safe escort programs available for students walking alone at night?\"\n",
      "Alumni Network\n",
      "\"How active and engaged is the alumni network?\"\n",
      "Alumni Network\n",
      "\"What industries and companies are alumni primarily employed in?\"\n",
      "Alumni Network\n",
      "\"How accessible are alumni for networking and mentorship opportunities?\"\n",
      "Alumni Network\n",
      "\"Does the university have a formal alumni mentorship program?\"\n",
      "Alumni Network\n",
      "\"What kind of events and programs does the alumni network offer for current students?\"\n",
      "Alumni Network\n",
      "\"Are alumni geographically concentrated, or are they spread across the country/world?\"\n",
      "Alumni Network\n",
      "\"How responsive are alumni to inquiries from current students and recent graduates?\"\n",
      "Alumni Network\n",
      "\"Does the alumni network provide career resources like job postings or resume reviews?\"\n",
      "Alumni Network\n",
      "\"What is the alumni giving rate to the university and how does that impact student life?\"\n",
      "Alumni Network\n",
      "\"Can I easily connect with alumni working in my specific field of interest?\"\n",
      "Technology & Facilities\n",
      "\"Are there modern, well-equipped labs and workshops available for my program of study?\"\n",
      "Technology & Facilities\n",
      "\"What is the quality and availability of the Wi-Fi network across campus and in student housing?\"\n",
      "Technology & Facilities\n",
      "\"Are there sufficient and easily accessible charging stations for laptops and mobile devices in common areas?\"\n",
      "Technology & Facilities\n",
      "\"What types of software and online resources are available to students, and are they accessible remotely?\"\n",
      "Technology & Facilities\n",
      "\"Does the university have dedicated spaces for collaborative projects and group study sessions, equipped with technology like large displays and whiteboards?\"\n",
      "Technology & Facilities\n",
      "\"What are the library resources like, including online databases, e-books, and physical books, and are there librarians available to assist with research?\"\n",
      "Technology & Facilities\n",
      "\"How often are classrooms and lecture halls upgraded with new technology, and what kind of audio-visual equipment is available for presentations?\"\n",
      "Technology & Facilities\n",
      "\"What security measures are in place to protect student data and equipment on campus, including cybersecurity and physical security in labs and residence halls?\"\n",
      "Technology & Facilities\n",
      "\"Are there accessible and well-maintained facilities for students with disabilities, including assistive technology and accessible restrooms?\"\n",
      "Technology & Facilities\n",
      "\"What is the university's commitment to sustainable practices, such as energy efficiency and waste reduction, in its facilities and technology usage?\"\n",
      "Admission Requirements\n",
      "\"What are the specific GPA requirements for my program of interest?\"\n",
      "Admission Requirements\n",
      "\"Are standardized tests like the SAT or ACT required, and if so, what are the minimum score expectations?\"\n",
      "Admission Requirements\n",
      "\"What are the prerequisites for my chosen major, and can I still apply if I'm missing one or two?\"\n",
      "Admission Requirements\n",
      "\"Does the university offer conditional admission for students who don't meet all requirements?\"\n",
      "Admission Requirements\n",
      "\"What is the application deadline, and are there different deadlines for different programs or application types?\"\n",
      "Admission Requirements\n",
      "\"What documents are required for the application, such as transcripts, letters of recommendation, and personal essays?\"\n",
      "Admission Requirements\n",
      "\"Are there any additional requirements for international students, such as English language proficiency tests or visa documentation?\"\n",
      "Admission Requirements\n",
      "\"What are the criteria used to evaluate applications, and how heavily weighted are different factors like GPA, test scores, and extracurricular activities?\"\n",
      "Admission Requirements\n",
      "\"Is there an application fee, and are fee waivers available for students with financial need?\"\n",
      "Admission Requirements\n",
      "\"What is the acceptance rate for my program of interest, and what are my chances of being admitted based on my academic profile?\"\n",
      "Application Process\n",
      "\"What are the specific admission requirements for my desired program?\"\n",
      "Application Process\n",
      "\"What is the application deadline and are there different deadlines for early admission or scholarships?\"\n",
      "Application Process\n",
      "\"What standardized tests are required or optional, and what are the recommended scores?\"\n",
      "Application Process\n",
      "\"What documents do I need to submit as part of my application (transcripts, letters of recommendation, personal essay, etc.)?\"\n",
      "Application Process\n",
      "\"How can I request transcripts from my previous institutions and have them sent to your university?\"\n",
      "Application Process\n",
      "\"What are you looking for in a strong personal essay or statement of purpose?\"\n",
      "Application Process\n",
      "\"How many letters of recommendation are required, and what qualities should my recommenders highlight?\"\n",
      "Application Process\n",
      "\"What is the application fee, and are there fee waivers available for eligible students?\"\n",
      "Application Process\n",
      "\"What is the process for checking the status of my application?\"\n",
      "Application Process\n",
      "\"Whom should I contact if I have questions about the application process or encounter technical difficulties?\"\n",
      "Campus Visit Options\n",
      "\"Are there different types of campus visits available, like group tours or personalized visits?\"\n",
      "Campus Visit Options\n",
      "\"What days and times are campus visits offered, and how far in advance should I book?\"\n",
      "Campus Visit Options\n",
      "\"Can I meet with professors or current students in my specific academic program during the visit?\"\n",
      "Campus Visit Options\n",
      "\"Is there an option to stay overnight on campus to get a better feel for student life?\"\n",
      "Campus Visit Options\n",
      "\"What COVID-19 safety protocols are in place for campus visits?\"\n",
      "Campus Visit Options\n",
      "\"Are there any virtual campus tour options available if I can't visit in person?\"\n",
      "Campus Visit Options\n",
      "\"How long does the average campus visit last, and what activities are included?\"\n",
      "Campus Visit Options\n",
      "\"Is there financial assistance available to help cover travel costs for campus visits?\"\n",
      "Campus Visit Options\n",
      "\"What should I wear and bring with me on the campus visit?\"\n",
      "Campus Visit Options\n",
      "\"Are there any specific information sessions or presentations scheduled during the visit that I should attend?\"\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "with open(\"questions.csv\", \"r\") as f_csv, open(\"answers.csv\", \"w\", newline='') as f_answers:\n",
    "    reader = csv.reader(f_csv)\n",
    "    writer = csv.writer(f_answers)\n",
    "\n",
    "    for row in reader:\n",
    "        topic, question = row\n",
    "        print(f\"{topic}\\n\\\"{question}\\\"\")\n",
    "\n",
    "        try:\n",
    "            answer = generate_answer(question)\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating answer: {e}\")\n",
    "            answer = \"Error generating answer\"\n",
    "\n",
    "        time.sleep(4)  # prevent rate limit\n",
    "        writer.writerow([topic, question, answer])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518dbba2-b593-48ca-abe0-ea8b2423bd19",
   "metadata": {},
   "source": [
    "# Finetune Llama 3.2 1B model\n",
    "\n",
    "Now use your SUTD QA dataset training data set to finetune a smaller Llama 3.2 1B LLM using parameter-efficient finetuning (PEFT). \n",
    "We recommend the unsloth library but you are free to choose other frameworks. You can decide the parameters for the finetuning. \n",
    "Push your finetuned model to Huggingface. \n",
    "\n",
    "Then we will compare the finetuned and non-finetuned LLMs with and without RAG to see if we were able to improve the SUTD chatbot answer quality. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a684028-8dec-4297-a2c4-f659d2f32a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: False\n",
      "CUDA is still not available. We'll need to use a CPU approach.\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and which version\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is still not available. We'll need to use a CPU approach.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa69d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use the simpler token-based approach\n",
    "from huggingface_hub import login\n",
    "login(token=\"HUGGING_FACE_AUTHENTICATION_TOKEN\")  # Replace with your actual token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4268373a-9d77-4787-a0d7-a6df23cd94de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN DATASET INFO:\n",
      "Shape: (160, 3)\n",
      "Column names: ['Topic', 'Question', 'Answer']\n",
      "\n",
      "First 5 rows:\n",
      "                                            Topic  \\\n",
      "0                 Student clubs and organizations   \n",
      "1                 Campus culture and student life   \n",
      "2                 Internship and career prospects   \n",
      "3            Sustainability initiatives on campus   \n",
      "4  Admission requirements and application process   \n",
      "\n",
      "                                            Question  \\\n",
      "0  How easy is it to start a new club if my area ...   \n",
      "1  How would you describe the typical student lif...   \n",
      "2  What percentage of SUTD graduates secure inter...   \n",
      "3  Are there any specific sustainability-related ...   \n",
      "4  Does SUTD offer any financial aid or scholarsh...   \n",
      "\n",
      "                                              Answer  \n",
      "0  Starting a new club at SUTD is relatively stra...  \n",
      "1  SUTD's student lifestyle is characterized by a...  \n",
      "2  There's no publicly available, precise percent...  \n",
      "3  SUTD doesn't have explicitly named clubs solel...  \n",
      "4  Yes, SUTD offers several financial aid and sch...  \n",
      "\n",
      "==================================================\n",
      "\n",
      "TEST DATASET INFO:\n",
      "Shape: (40, 3)\n",
      "Column names: ['Topic', 'Question', 'Answer']\n",
      "\n",
      "First 5 rows:\n",
      "                                   Topic  \\\n",
      "0     SUTD's emphasis on design thinking   \n",
      "1        Campus culture and student life   \n",
      "2  Research opportunities and facilities   \n",
      "3  Research opportunities and facilities   \n",
      "4        Internship and career prospects   \n",
      "\n",
      "                                            Question  \\\n",
      "0  What specific design thinking methodologies ar...   \n",
      "1  What opportunities exist for international stu...   \n",
      "2  What specific research labs or centers align w...   \n",
      "3  What is the typical student-to-faculty ratio i...   \n",
      "4  Can you provide examples of recent successful ...   \n",
      "\n",
      "                                              Answer  \n",
      "0  SUTD deeply integrates design thinking through...  \n",
      "1  SUTD boasts a highly internationalized campus ...  \n",
      "2  SUTD's research strengths in sustainable mater...  \n",
      "3  SUTD doesn't publish a specific, university-wi...  \n",
      "4  Please specify the \"[Specific Industry]\" you'r...  \n"
     ]
    }
   ],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "try:\n",
    "    # Try with UTF-8 encoding first\n",
    "    train_data = pd.read_csv(\"qa_train_dataset.csv\", encoding=\"utf-8\")\n",
    "    test_data = pd.read_csv(\"qa_test_dataset.csv\", encoding=\"utf-8\")\n",
    "except UnicodeDecodeError:\n",
    "    # If that fails, try with latin1 encoding\n",
    "    train_data = pd.read_csv(\"qa_train_dataset.csv\", encoding=\"latin1\")\n",
    "    test_data = pd.read_csv(\"qa_test_dataset.csv\", encoding=\"latin1\")\n",
    "\n",
    "# Display information about the dataframes\n",
    "print(\"TRAIN DATASET INFO:\")\n",
    "print(f\"Shape: {train_data.shape}\")\n",
    "print(\"Column names:\", train_data.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(train_data.head(5))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"TEST DATASET INFO:\")\n",
    "print(f\"Shape: {test_data.shape}\")\n",
    "print(\"Column names:\", test_data.columns.tolist())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(test_data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff291f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load datasets\n",
      "Loaded 160 training examples 40 examples\n",
      "tokenizer: meta-llama/Llama-3.2-1B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402318edeed3463aa75739cd9e4ddc14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37049a703092410b96d10b6441874ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bff18844fd75456488ed509c350a45f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecaf21856194ecfb14aac41ca98d6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e1ed20e8544c43aee0169f7c0c500a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: meta-llama/Llama-3.2-1B\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69eb3e1f661d4464bed9085f305d9833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0927bfb1f83c45179908f9d790f2659b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52ad787e31e4128b94e2ba7952fb926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lora-ed\n",
      "bruh\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "fp16 mixed precision requires a GPU (not 'mps').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 98\u001b[0m\n\u001b[1;32m     92\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForLanguageModeling(\n\u001b[1;32m     93\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     94\u001b[0m     mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m  \n\u001b[1;32m     95\u001b[0m )\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbruh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     99\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    100\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m    101\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_train,\n\u001b[1;32m    102\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_test,\n\u001b[1;32m    103\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainignn started!!!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:463\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeepspeed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_in_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_accelerator_and_postprocess()\n\u001b[1;32m    465\u001b[0m \u001b[38;5;66;03m# memory metrics - must set up as early as possible\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_memory_tracker \u001b[38;5;241m=\u001b[39m TrainerMemoryTracker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mskip_memory_metrics)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/trainer.py:5156\u001b[0m, in \u001b[0;36mTrainer.create_accelerator_and_postprocess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   5153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequires accelerate>1.3.0 to use Tensor Parallelism.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   5155\u001b[0m \u001b[38;5;66;03m# create accelerator object\u001b[39;00m\n\u001b[0;32m-> 5156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m Accelerator(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   5157\u001b[0m \u001b[38;5;66;03m# some Trainer classes need to use `gather` instead of `gather_for_metrics`, thus we store a flag\u001b[39;00m\n\u001b[1;32m   5158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather_for_metrics\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/accelerate/accelerator.py:555\u001b[0m, in \u001b[0;36mAccelerator.__init__\u001b[0;34m(self, device_placement, split_batches, mixed_precision, gradient_accumulation_steps, cpu, dataloader_config, deepspeed_plugin, fsdp_plugin, torch_tp_plugin, megatron_lm_plugin, rng_types, log_with, project_dir, project_config, gradient_accumulation_plugin, step_scheduler_with_optimizer, kwargs_handlers, dynamo_backend, dynamo_plugin, deepspeed_plugins)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnative_amp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m    546\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    547\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msdaa\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    554\u001b[0m ) \u001b[38;5;129;01mor\u001b[39;00m is_torch_xla_available(check_is_tpu\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfp16 mixed precision requires a GPU (not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    556\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler\u001b[38;5;241m.\u001b[39mto_kwargs() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    558\u001b[0m \u001b[38;5;66;03m# FSDP2 doesn't use ShardedGradScaler, don't want to modify `get_grad_scaler`, rather create a simple utility\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: fp16 mixed precision requires a GPU (not 'mps')."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "print(\"load datasets\")\n",
    "train_data = pd.read_csv(\"qa_train_dataset.csv\")\n",
    "test_data = pd.read_csv(\"qa_test_dataset.csv\")\n",
    "\n",
    "print(f\"Loaded {len(train_data)} training examples {len(test_data)} examples\")\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "print(f\"tokenizer: {model_name}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "def create_prompt(question, answer):\n",
    "    return f\"<|system|>\\nYou are a helpful assistant for SUTD (Singapore University of Technology and Design).\\n<|user|>\\n{question}\\n<|assistant|>\\n{answer}\"\n",
    "\n",
    "train_texts = [create_prompt(row[\"Question\"], row[\"Answer\"]) for _, row in train_data.iterrows()]\n",
    "test_texts = [create_prompt(row[\"Question\"], row[\"Answer\"]) for _, row in test_data.iterrows()]\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\"text\": train_texts})\n",
    "test_dataset = Dataset.from_dict({\"text\": test_texts})\n",
    "\n",
    "print(\"tokenizer\")\n",
    "tokenized_train = train_dataset.map(\n",
    "    tokenize_function, \n",
    "    batched=True,\n",
    "    num_proc=1,  \n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "tokenized_test = test_dataset.map(\n",
    "    tokenize_function, \n",
    "    batched=True,\n",
    "    num_proc=1,  \n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"]\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, peft_config)\n",
    "print(\"lora-ed\")\n",
    "\n",
    "output_dir = \"./llama3_sutd_qa_finetuned\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    optim=\"adamw_torch\",\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=10,\n",
    "    num_train_epochs=3,\n",
    "    max_steps=200,\n",
    "    fp16=True,\n",
    "    save_total_limit=3,\n",
    "    push_to_hub=False,\n",
    "    dataloader_num_workers=0,  \n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  \n",
    ")\n",
    "\n",
    "print(\"bruh\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Trainignn started!!!\")\n",
    "trainer.train()\n",
    "\n",
    "print(\"Model Ssaved\")\n",
    "# trainer.save_model(output_dir)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "# After training is complete, save the complete model\n",
    "trainer.save_model(output_dir)\n",
    "from huggingface_hub import login\n",
    "login(token=\"HUGGING_FACE_AUTHENTICATION_TOKEN\") \n",
    "# To push the LoRA adapter to Hugging Face Hub\n",
    "model.push_to_hub(\"reenee1601/llama-3.2-1B-sutdqa\")\n",
    "tokenizer.push_to_hub(\"reenee1601/llama-3.2-1B-sutdqa\")\n",
    "\n",
    "# Alternatively, if you want to merge the adapter weights with the base model before pushing:\n",
    "from peft import PeftModel\n",
    "\n",
    "# Load the base model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Load the PEFT model\n",
    "peft_model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "\n",
    "# Merge adapter weights with base model\n",
    "merged_model = peft_model.merge_and_unload()\n",
    "\n",
    "# Push the merged model to Hub\n",
    "merged_model.push_to_hub(\"reenee1601/llama-3.2-1B-sutdqa-merged\")\n",
    "tokenizer.push_to_hub(\"reenee1601/llama-3.2-1B-sutdqa-merged\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d582c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or use the simpler token-based approach\n",
    "from huggingface_hub import login\n",
    "login(token=\"HUGGING_FACE_AUTHENTICATION_TOKEN\")  # Replace with your actual token\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a6d11f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872060b25f9442609d76c4e4933bb5c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/52.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600791bafc4f4ec6aca45fdeb1b96715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf52ba4f44e41bc9ba1c950005c50ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a847fffdff8455f9e6439069da8af12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "LoraConfig.__init__() got an unexpected keyword argument 'corda_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model_finetune \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreenee1601/llama-3.2-1B-sutdqa\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m tokenizer_finetune \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_finetune)\n\u001b[0;32m---> 26\u001b[0m llm_finetune \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_finetune,\n\u001b[1;32m     29\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer_finetune,\n\u001b[1;32m     30\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     31\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Use first GPU if available\u001b[39;00m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Test with a sample question\u001b[39;00m\n\u001b[1;32m     35\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is special about SUTD?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/__init__.py:942\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 942\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    943\u001b[0m         adapter_path \u001b[38;5;28;01mif\u001b[39;00m adapter_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model,\n\u001b[1;32m    944\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[1;32m    945\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    946\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[1;32m    947\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    950\u001b[0m     )\n\u001b[1;32m    952\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    953\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:291\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    293\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:571\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    570\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    572\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:4482\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4479\u001b[0m     model\u001b[38;5;241m.\u001b[39mhf_quantizer \u001b[38;5;241m=\u001b[39m hf_quantizer\n\u001b[1;32m   4481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _adapter_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4482\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_adapter(\n\u001b[1;32m   4483\u001b[0m         _adapter_model_path,\n\u001b[1;32m   4484\u001b[0m         adapter_name\u001b[38;5;241m=\u001b[39madapter_name,\n\u001b[1;32m   4485\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   4486\u001b[0m         adapter_kwargs\u001b[38;5;241m=\u001b[39madapter_kwargs,\n\u001b[1;32m   4487\u001b[0m     )\n\u001b[1;32m   4489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_loading_info:\n\u001b[1;32m   4490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m from_pt:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/integrations/peft.py:212\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, low_cpu_mem_usage, is_trainable, adapter_kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m adapter_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapter model file not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeft_model_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure you are passing the correct path to the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapter model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m PeftConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    213\u001b[0m         peft_model_id,\n\u001b[1;32m    214\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_kwargs,\n\u001b[1;32m    216\u001b[0m     )\n\u001b[1;32m    217\u001b[0m     peft_config\u001b[38;5;241m.\u001b[39minference_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_trainable\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Create and add fresh new adapters into the model.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/peft/config.py:151\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m loaded_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json_file(config_file)\n\u001b[1;32m    150\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclass_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloaded_attributes}\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_peft_type(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/peft/config.py:118\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_peft_type\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     config_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: LoraConfig.__init__() got an unexpected keyword argument 'corda_config'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Load the base model\n",
    "model_base = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(model_base)\n",
    "llm_base = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_base,\n",
    "    tokenizer=tokenizer_base,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\"  # Use first GPU if available\n",
    ")\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model_finetune = \"reenee1601/llama-3.2-1B-sutdqa\"\n",
    "tokenizer_finetune = AutoTokenizer.from_pretrained(model_finetune)\n",
    "llm_finetune = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_finetune,\n",
    "    tokenizer=tokenizer_finetune,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\"  # Use first GPU if available\n",
    ")\n",
    "\n",
    "# Test with a sample question\n",
    "query = \"What is special about SUTD?\"\n",
    "\n",
    "print(\"\\nQuestion:\", query)\n",
    "response_base = llm_base(query, max_new_tokens=512, do_sample=True, temperature=0.7)\n",
    "print(\"Answer base:\", response_base[0]['generated_text'])\n",
    "\n",
    "print(\"---------\")\n",
    "response_finetune = llm_finetune(query, max_new_tokens=512, do_sample=True, temperature=0.7)\n",
    "print(\"Answer finetune:\", response_finetune[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8eb8417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b45bbedcbf94a3aa1428a0d516d89cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './llama3_sutd_qa_finetuned'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:424\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m     hf_hub_download(\n\u001b[1;32m    425\u001b[0m         path_or_repo_id,\n\u001b[1;32m    426\u001b[0m         filenames[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    427\u001b[0m         subfolder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(subfolder) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m subfolder,\n\u001b[1;32m    428\u001b[0m         repo_type\u001b[38;5;241m=\u001b[39mrepo_type,\n\u001b[1;32m    429\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    430\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    431\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[1;32m    432\u001b[0m         force_download\u001b[38;5;241m=\u001b[39mforce_download,\n\u001b[1;32m    433\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[1;32m    434\u001b[0m         resume_download\u001b[38;5;241m=\u001b[39mresume_download,\n\u001b[1;32m    435\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    436\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    437\u001b[0m     )\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './llama3_sutd_qa_finetuned'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load your fine-tuned model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./llama3_sutd_qa_finetuned\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_path)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Push to Hugging Face Hub - replace YOUR_HF_NAME with your Hugging Face username\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreenee1601/llama-3.2-1B-sutdqa\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:492\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m    491\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m    493\u001b[0m             pretrained_model_name_or_path,\n\u001b[1;32m    494\u001b[0m             CONFIG_NAME,\n\u001b[1;32m    495\u001b[0m             _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m             _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m             _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    498\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[1;32m    499\u001b[0m         )\n\u001b[1;32m    500\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:266\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_file\u001b[39m(\n\u001b[1;32m    209\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    210\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    212\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    213\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    267\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:471\u001b[0m, in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    467\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# Now we try to recover if we can find all files correctly in the cache\u001b[39;00m\n\u001b[1;32m    470\u001b[0m resolved_files \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 471\u001b[0m     _get_cache_file_to_return(path_or_repo_id, filename, cache_dir, revision) \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m full_filenames\n\u001b[1;32m    472\u001b[0m ]\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m resolved_files):\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resolved_files\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/hub.py:134\u001b[0m, in \u001b[0;36m_get_cache_file_to_return\u001b[0;34m(path_or_repo_id, full_filename, cache_dir, revision)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_cache_file_to_return\u001b[39m(\n\u001b[1;32m    131\u001b[0m     path_or_repo_id: \u001b[38;5;28mstr\u001b[39m, full_filename: \u001b[38;5;28mstr\u001b[39m, cache_dir: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, revision: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    132\u001b[0m ):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# We try to see if we have a cached version (not up to date):\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m try_to_load_from_cache(path_or_repo_id, full_filename, cache_dir\u001b[38;5;241m=\u001b[39mcache_dir, revision\u001b[38;5;241m=\u001b[39mrevision)\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m resolved_file \u001b[38;5;241m!=\u001b[39m _CACHED_NO_EXIST:\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg_name, arg_value \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mzip\u001b[39m(signature\u001b[38;5;241m.\u001b[39mparameters, args),  \u001b[38;5;66;03m# Args values\u001b[39;00m\n\u001b[1;32m    103\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mitems(),  \u001b[38;5;66;03m# Kwargs values\u001b[39;00m\n\u001b[1;32m    104\u001b[0m ):\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m         has_token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot have -- or .. in repo_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './llama3_sutd_qa_finetuned'."
     ]
    }
   ],
   "source": [
    "# Login to Hugging Face Hub\n",
    "from huggingface_hub import login\n",
    "login()  # You'll need to enter your token\n",
    "\n",
    "# Push your model to Hugging Face Hub\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model_path = \"./llama3_sutd_qa_finetuned\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# Push to Hugging Face Hub - replace YOUR_HF_NAME with your Hugging Face username\n",
    "model.push_to_hub(\"reenee1601/llama-3.2-1B-sutdqa\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "tokenizer.push_to_hub(\"reenee1601/llama-3.2-1B-sutdqa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5bedb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LoraConfig.__init__() got an unexpected keyword argument 'corda_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m model_finetune \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreenee1601/llama-3.2-1B-sutdqa\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m tokenizer_finetune \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_finetune)\n\u001b[0;32m---> 26\u001b[0m llm_finetune \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-generation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel_finetune,\n\u001b[1;32m     29\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer_finetune,\n\u001b[1;32m     30\u001b[0m     torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     31\u001b[0m     device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Use first GPU if available\u001b[39;00m\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Test with a sample question\u001b[39;00m\n\u001b[1;32m     35\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat is special about SUTD?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/__init__.py:942\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    941\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 942\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m infer_framework_load_model(\n\u001b[1;32m    943\u001b[0m         adapter_path \u001b[38;5;28;01mif\u001b[39;00m adapter_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m model,\n\u001b[1;32m    944\u001b[0m         model_classes\u001b[38;5;241m=\u001b[39mmodel_classes,\n\u001b[1;32m    945\u001b[0m         config\u001b[38;5;241m=\u001b[39mconfig,\n\u001b[1;32m    946\u001b[0m         framework\u001b[38;5;241m=\u001b[39mframework,\n\u001b[1;32m    947\u001b[0m         task\u001b[38;5;241m=\u001b[39mtask,\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m    950\u001b[0m     )\n\u001b[1;32m    952\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    953\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/pipelines/base.py:291\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    293\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:571\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    570\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[0;32m--> 571\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    572\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    573\u001b[0m     )\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:279\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:4482\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4479\u001b[0m     model\u001b[38;5;241m.\u001b[39mhf_quantizer \u001b[38;5;241m=\u001b[39m hf_quantizer\n\u001b[1;32m   4481\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _adapter_model_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4482\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_adapter(\n\u001b[1;32m   4483\u001b[0m         _adapter_model_path,\n\u001b[1;32m   4484\u001b[0m         adapter_name\u001b[38;5;241m=\u001b[39madapter_name,\n\u001b[1;32m   4485\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   4486\u001b[0m         adapter_kwargs\u001b[38;5;241m=\u001b[39madapter_kwargs,\n\u001b[1;32m   4487\u001b[0m     )\n\u001b[1;32m   4489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_loading_info:\n\u001b[1;32m   4490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m from_pt:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/transformers/integrations/peft.py:212\u001b[0m, in \u001b[0;36mPeftAdapterMixin.load_adapter\u001b[0;34m(self, peft_model_id, adapter_name, revision, token, device_map, max_memory, offload_folder, offload_index, peft_config, adapter_state_dict, low_cpu_mem_usage, is_trainable, adapter_kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m adapter_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapter model file not found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeft_model_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Make sure you are passing the correct path to the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madapter model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    210\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m PeftConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    213\u001b[0m         peft_model_id,\n\u001b[1;32m    214\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39madapter_kwargs,\n\u001b[1;32m    216\u001b[0m     )\n\u001b[1;32m    217\u001b[0m     peft_config\u001b[38;5;241m.\u001b[39minference_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m is_trainable\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# Create and add fresh new adapters into the model.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/peft/config.py:151\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m loaded_attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_json_file(config_file)\n\u001b[1;32m    150\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mclass_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloaded_attributes}\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_peft_type(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/peft/config.py:118\u001b[0m, in \u001b[0;36mPeftConfigMixin.from_peft_type\u001b[0;34m(cls, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     config_cls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m config_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: LoraConfig.__init__() got an unexpected keyword argument 'corda_config'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Load the base model\n",
    "model_base = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(model_base)\n",
    "llm_base = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_base,\n",
    "    tokenizer=tokenizer_base,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\"  # Use first GPU if available\n",
    ")\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model_finetune = \"reenee1601/llama-3.2-1B-sutdqa\"\n",
    "tokenizer_finetune = AutoTokenizer.from_pretrained(model_finetune)\n",
    "llm_finetune = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_finetune,\n",
    "    tokenizer=tokenizer_finetune,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\"  # Use first GPU if available\n",
    ")\n",
    "\n",
    "# Test with a sample question\n",
    "query = \"What is special about SUTD?\"\n",
    "\n",
    "print(\"\\nQuestion:\", query)\n",
    "response_base = llm_base(query, max_new_tokens=512, do_sample=True, temperature=0.7)\n",
    "print(\"Answer base:\", response_base[0]['generated_text'])\n",
    "\n",
    "print(\"---------\")\n",
    "response_finetune = llm_finetune(query, max_new_tokens=512, do_sample=True, temperature=0.7)\n",
    "print(\"Answer finetune:\", response_finetune[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adedd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated(0) / 1024**2:.2f} MB\")\n",
    "    print(f\"Memory reserved: {torch.cuda.memory_reserved(0) / 1024**2:.2f} MB\")\n",
    "\n",
    "# Load your fine-tuned model\n",
    "model_finetune = \"reenee1601/llama-3.2-1B-sutdqa\"\n",
    "tokenizer_finetune = AutoTokenizer.from_pretrained(model_finetune)\n",
    "llm_finetune = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_finetune,\n",
    "    tokenizer=tokenizer_finetune,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\"  # Use first GPU if available\n",
    ")\n",
    "\n",
    "# Test with a sample question\n",
    "query = \"What is special about SUTD?\"\n",
    "\n",
    "# print(\"\\nQuestion:\", query)\n",
    "# response_base = llm_base(query, max_new_tokens=512, do_sample=True, temperature=0.7)\n",
    "# print(\"Answer base:\", response_base[0]['generated_text'])\n",
    "\n",
    "print(\"---------\")\n",
    "response_finetune = llm_finetune(query, max_new_tokens=512, do_sample=True, temperature=0.7)\n",
    "print(\"Answer finetune:\", response_finetune[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e2531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try out the llms\n",
    "\n",
    "query = \"What is special about SUTD?\"\n",
    "\n",
    "print(\"Question:\", query)\n",
    "response_base = llm_base.invoke(query,  pipeline_kwargs={\"max_new_tokens\": 512})\n",
    "print(\"Answer base:\", response_base)\n",
    "\n",
    "print(\"---------\")\n",
    "response_finetune = llm_finetune.invoke(query, pipeline_kwargs={\"max_new_tokens\": 512})\n",
    "print(\"Answer finetune:\", response_finetune)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc277373",
   "metadata": {},
   "source": [
    "# Integrate and evaluate\n",
    "\n",
    "Now integrate both the non-finetuned Llama 3.2 1B model and your finetuned model into your SUTD chatbot RAG system. \n",
    "Generate responses to the 20 questions you have collected in assignment 3 using these 4 appraoches\n",
    "1. non-finetuned Llama 3.2 1B model without RAG\n",
    "2. finetuned Llama 3.2 1B SUTD QA model without RAG\n",
    "3. non-finetuned Llama 3.2 1B model with RAG\n",
    "4. finetuned Llama 3.2 1B SUTD QA model with RAG\n",
    "\n",
    "Compare the responses and decide what system produces the most accurate and high quality responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da455368",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer,pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import numpy\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from pypdf import PdfReader\n",
    "import os\n",
    "from os import listdir\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re \n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from peft import PeftModel, PeftConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfcf8ce",
   "metadata": {},
   "source": [
    "## Load Base Model & Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3ea208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model identifiers\n",
    "model_base_id = \"meta-llama/Llama-3.2-1B\"\n",
    "model_finetune_id = \"reenee1601/llama-3.2-1B-sutdqa-merged\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ----------------------------\n",
    "# Load BASE model + tokenizer\n",
    "# ----------------------------\n",
    "tokenizer_base = AutoTokenizer.from_pretrained(\n",
    "    model_base_id,\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure base tokenizer has padding token\n",
    "if tokenizer_base.pad_token is None:\n",
    "    tokenizer_base.pad_token = tokenizer_base.eos_token\n",
    "    tokenizer_base.pad_token_id = tokenizer_base.eos_token_id\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_base_id,\n",
    "    torch_dtype=torch.float32,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Load FINETUNED model + tokenizer\n",
    "# ----------------------------\n",
    "tokenizer_finetune = AutoTokenizer.from_pretrained(\n",
    "    model_finetune_id,\n",
    "    padding_side=\"left\"\n",
    ")\n",
    "\n",
    "# Ensure finetuned tokenizer has padding token\n",
    "if tokenizer_finetune.pad_token is None:\n",
    "    tokenizer_finetune.pad_token = tokenizer_finetune.eos_token\n",
    "    tokenizer_finetune.pad_token_id = tokenizer_finetune.eos_token_id\n",
    "\n",
    "finetuned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_finetune_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# Create text-generation pipelines\n",
    "# ----------------------------\n",
    "llm_base = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=base_model,\n",
    "    tokenizer=tokenizer_base,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.4,\n",
    "    pad_token_id=tokenizer_base.pad_token_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\",\n",
    ")\n",
    "\n",
    "llm_finetune = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=finetuned_model,\n",
    "    tokenizer=tokenizer_finetune,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.4,\n",
    "    pad_token_id=tokenizer_finetune.pad_token_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=0 if device == \"cuda\" else \"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa954be",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What courses are available in SUTD?\"\n",
    "\n",
    "formatted_input = f\"Question: {query}\\nYou are a helpful and friendly assistant who provides detailed and informative answers to prospective students about their queries regarding the Singapore University of Technology and Design (SUTD). Elaborate on your response while keeping it concise and relevant. Answer:\"\n",
    "\n",
    "# Generate response\n",
    "response = llm_base(\n",
    "    formatted_input,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.4,\n",
    "    pad_token_id=tokenizer_base.pad_token_id\n",
    ")\n",
    "\n",
    "print({\"answer\": response[0]['generated_text'].split(\"Answer:\")[-1].strip()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bed8e0",
   "metadata": {},
   "source": [
    "## Non-Rag\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54005447",
   "metadata": {},
   "source": [
    "### 1. Non-finetuned Llama 3.2 1B model without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5838d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "            \"What are the admissions deadlines for SUTD?\",\n",
    "            \"Is there financial aid available?\",\n",
    "            \"What is the minimum score for the Mother Tongue Language?\",\n",
    "            \"Do I require reference letters?\",\n",
    "            \"Can polytechnic diploma students apply?\",\n",
    "            \"Do I need SAT score?\",\n",
    "            \"How many PhD students does SUTD have?\",\n",
    "            \"How much are the tuition fees for Singaporeans?\",\n",
    "            \"How much are the tuition fees for international students?\",\n",
    "            \"Is there a minimum CAP?\",\n",
    "            \"If I am a polytechnic student with CGPA 3.0, am I still able to go SUTD?\",\n",
    "            \"Is first year housing compulsory?\",\n",
    "            \"Is ILP compulsory?\",\n",
    "            \"Does SUTD help me in sourcing internships or jobs?\",\n",
    "            \"I want to create a startup during my undergraduate years. What assistance does SUTD provide?\",\n",
    "            \"I am new to programming but I want to join Computer Science & Design. Will SUTD provide any bridging courses in the first year?\",\n",
    "            \"I want to work in cybersecurity after graduation. What course and modules should I take at SUTD?\",\n",
    "            \"What career path does DAI open for me?\",\n",
    "            \"Who can I contact to query about my admission application?\",\n",
    "            \"When does school start for freshmore?\"\n",
    "            ]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"query\", \"answer\"])\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    formatted_input = f\"Question: {question}\\nYou are a helpful and friendly assistant who provides detailed and informative answers to prospective students about their queries regarding the Singapore University of Technology and Design (SUTD). Elaborate on your response while keeping it concise and relevant. Answer:\"\n",
    "    \n",
    "    response = llm_base(\n",
    "        formatted_input,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.4,\n",
    "        pad_token_id=tokenizer_base.pad_token_id\n",
    "    )\n",
    "    \n",
    "    answer = response[0]['generated_text'].split(\"Answer:\")[-1].strip()\n",
    "    df.loc[len(df)] = [question, answer]\n",
    "\n",
    "df.to_csv('results_base.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9301c",
   "metadata": {},
   "source": [
    "### 2. Finetuned Llama 3.2 1B SUTD QA model without RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ebe860",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "            \"What are the admissions deadlines for SUTD?\",\n",
    "            \"Is there financial aid available?\",\n",
    "            \"What is the minimum score for the Mother Tongue Language?\",\n",
    "            \"Do I require reference letters?\",\n",
    "            \"Can polytechnic diploma students apply?\",\n",
    "            \"Do I need SAT score?\",\n",
    "            \"How many PhD students does SUTD have?\",\n",
    "            \"How much are the tuition fees for Singaporeans?\",\n",
    "            \"How much are the tuition fees for international students?\",\n",
    "            \"Is there a minimum CAP?\",\n",
    "            \"If I am a polytechnic student with CGPA 3.0, am I still able to go SUTD?\",\n",
    "            \"Is first year housing compulsory?\",\n",
    "            \"Is ILP compulsory?\",\n",
    "            \"Does SUTD help me in sourcing internships or jobs?\",\n",
    "            \"I want to create a startup during my undergraduate years. What assistance does SUTD provide?\",\n",
    "            \"I am new to programming but I want to join Computer Science & Design. Will SUTD provide any bridging courses in the first year?\",\n",
    "            \"I want to work in cybersecurity after graduation. What course and modules should I take at SUTD?\",\n",
    "            \"What career path does DAI open for me?\",\n",
    "            \"Who can I contact to query about my admission application?\",\n",
    "            \"When does school start for freshmore?\"\n",
    "            ]\n",
    "\n",
    "df = pd.DataFrame(columns=[\"query\", \"answer\"])\n",
    "\n",
    "for question in tqdm(questions):\n",
    "    formatted_input = f\"Question: {question}\\nYou are a helpful and friendly assistant who provides detailed and informative answers to prospective students about their queries regarding the Singapore University of Technology and Design (SUTD). Elaborate on your response while keeping it concise and relevant. Answer:\"\n",
    "    \n",
    "    response = llm_finetune(\n",
    "        formatted_input,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.4,\n",
    "        pad_token_id=tokenizer_finetune.pad_token_id\n",
    "    )\n",
    "    \n",
    "    answer = response[0]['generated_text'].split(\"Answer:\")[-1].strip()\n",
    "    df.loc[len(df)] = [question, answer]\n",
    "\n",
    "df.to_csv('results_finetune.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428e6717",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e85c6d6",
   "metadata": {},
   "source": [
    "### Download Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90011775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separated by different loaders because different webpage has content on different html element\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://en.wikipedia.org/wiki/Singapore_University_of_Technology_and_Design\", \n",
    "            \"https://www.sutd.edu.sg/research/research-centres/designz/about/introduction/\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/fees/tuition-fees/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/fees/tuition-grant-eligibility/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/financial-estimates/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/education-expenses/student-insurance-scheme/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/appeal/\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/admission-requirements/overview\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/scholarship/sutd-administered/\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/scholarship/external-sponsored/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/scholarship/awards/sutd-design-innovator-award/\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/financing-options-and-aid/financial-aid/overview/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/financing-options-and-aid/other-financing-options/overview#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/financing-options-and-aid/sutd-community-grant/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/early-matriculation/\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/integrated-learning-programme/\",\n",
    "            \"https://www.sutd.edu.sg/campus-life/student-life/student-organisations-fifth-row/\",\n",
    "            \"https://www.sutd.edu.sg/campus-life/student-life/part-time-work-scheme/\",\n",
    "            \"https://www.sutd.edu.sg/campus-life/student-life/student-awards/student-achievement-awards/overview/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/admission-requirements/international-qualifications\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/application-guide/\",\n",
    "            \"https://www.sutd.edu.sg/istd/139-2/\",\n",
    "                \"https://www.sutd.edu.sg/course/10-013-modelling-and-analysis/\",\n",
    "            \"https://www.sutd.edu.sg/course/10-015-physical-world/\",\n",
    "            \"https://www.sutd.edu.sg/course/10-014-computational-thinking-for-design/\",\n",
    "            \"https://www.sutd.edu.sg/course/02-001-global-humanities-literature-philosophy-and-ethics/\",\n",
    "            \"https://www.sutd.edu.sg/course/10-018-modelling-space-and-systems/\",\n",
    "            \"https://www.sutd.edu.sg/course/10-017-technological-world/\",\n",
    "            \"https://www.sutd.edu.sg/course/10-016-science-for-a-sustainable-world/\",\n",
    "            \"https://www.sutd.edu.sg/course/03-007-design-thinking-and-innovation/\"\n",
    "            ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            name=(\"main\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=2#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=3#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=4#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=5#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=6#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=7faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=8#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=9#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/faq/?faq-category=1655%2C1650%2C1653%2C1654%2C1652%2C1753%2C1586%2C1740%2C937%2C1749%2C815%2C1750%2C1751%2C1752%2C1754%2C1755%2C1756%2C1757&paged=10#faq-listing\",\n",
    "            ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            name=(\"p\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs_faq = loader.load()\n",
    "\n",
    "docs += docs_faq\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.sutd.edu.sg/campus-life/housing/freshmore-terms-1-2/rooms-and-amenities/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/campus-life/housing/freshmore-terms-1-2/check-in-out-ay2025/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/campus-life/housing/freshmore-terms-1-2/payment-ay2025/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/campus-life/housing/freshmore-terms-1-2/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/local-diploma/criteria-for-admission\",\n",
    "            \"https://www.sutd.edu.sg/admissions/undergraduate/local-diploma/application-timeline/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/istd/education/undergraduate/faq/why-istd/#tabs\",\n",
    "            ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            id=(\"component-grid-group\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "extra = loader.load()\n",
    "docs+=extra\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.sutd.edu.sg/istd/education/undergraduate/faq/faq/#tabs\",\n",
    "            \"https://www.sutd.edu.sg/istd/education/undergraduate/faq/faq/?paged=2#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/esd/education/undergraduate/faq/?post_tag=54\",\n",
    "            \"https://www.sutd.edu.sg/epd/education/undergraduate/faq/?post_tag=719\",\n",
    "            \"https://www.sutd.edu.sg/epd/education/undergraduate/faq/?post_tag=719&paged=2#faq-listing\",\n",
    "            \"https://www.sutd.edu.sg/epd/education/undergraduate/faq/?post_tag=719&paged=3#faq-listing\",\n",
    "            ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            id=(\"rich-text-generator\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "extra = loader.load()\n",
    "docs+=extra\n",
    "\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://www.sutd.edu.sg/education/undergraduate/freshmore-subjects/\",\n",
    "            ),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"acf-innerblocks-container\"),\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "\n",
    "extra = loader.load()\n",
    "docs+=extra\n",
    "\n",
    "def scrape_course(url):\n",
    "    try:\n",
    "        res = requests.get(url, timeout=10)\n",
    "        res.raise_for_status()\n",
    "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "        title_tag = soup.find(\"h1\")\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"No Title Found\"\n",
    "\n",
    "        rich_text_span = soup.find(\"span\", {\"id\": \"rich-text-generator\"})\n",
    "        description = \"\"\n",
    "        \n",
    "        if rich_text_span:\n",
    "            li_tags = rich_text_span.find_all(\"li\")\n",
    "            p_tags = rich_text_span.find_all(\"p\")\n",
    "            h_tags = rich_text_span.find_all(re.compile(\"^h[1-6]$\"))  \n",
    "\n",
    "            description = \"\\n\".join([tag.get_text(strip=True) for tag in li_tags + p_tags + h_tags])\n",
    "\n",
    "        if not description:\n",
    "            fallback_span = soup.find(\"span\", class_=\"richText richtext-paragraph-margin\")\n",
    "            first_paragraph = fallback_span.find(\"p\") if fallback_span else None\n",
    "\n",
    "            if not first_paragraph:\n",
    "                fallback_div = soup.find(\"div\", class_=\"wp-block-column is-vertically-aligned-center\")\n",
    "                first_paragraph = fallback_div.find(\"p\") if fallback_div else None\n",
    "\n",
    "            if not first_paragraph:\n",
    "                fallback_div = soup.find(\"div\", class_=\"wp-block-column\")\n",
    "                first_paragraph = fallback_div.find(\"p\") if fallback_div else None\n",
    "\n",
    "            if not first_paragraph:\n",
    "                list_items = soup.find_all(\"li\")\n",
    "                if list_items:\n",
    "                    first_paragraph = list_items[0].get_text(strip=True)\n",
    "\n",
    "            if first_paragraph:\n",
    "                description = first_paragraph\n",
    "\n",
    "        # Extract description\n",
    "        description = description if description else \"No Description Found\"\n",
    "        print(f\"Title: {title}\")\n",
    "        print(f\"Description: {description}\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "        return title, description\n",
    "\n",
    "    except Exception as e:\n",
    "        return \"Error\", f\"Failed to fetch: {url} - {str(e)}\"\n",
    "\n",
    "\n",
    "def save_to_html(course_data, output_file=\"courses.html\"):\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(\"<html><body><h1>Course Titles and Descriptions</h1>\")\n",
    "        for title, description in course_data:\n",
    "            file.write(f\"<h2>{title}</h2>\")\n",
    "            file.write(f\"<p>{description}</p>\")\n",
    "        file.write(\"</body></html>\")\n",
    "\n",
    "def scrape_courses_from_file(input_file=\"course_links.txt\"):\n",
    "    course_data = []\n",
    "    with open(input_file, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            url = line.strip()\n",
    "            if url:  \n",
    "                title, description = scrape_course(url)\n",
    "                course_data.append((title, description))\n",
    "    \n",
    "    return course_data\n",
    "\n",
    "course_data = scrape_courses_from_file()\n",
    "save_to_html(course_data)\n",
    "\n",
    "\n",
    "def scrape_local(link, about):\n",
    "    with open(link, encoding=\"utf-8\") as fp:\n",
    "        soup = BeautifulSoup(fp, 'html.parser')\n",
    "    \n",
    "    for course_tag in soup.find_all('h2'):\n",
    "        course_title = course_tag.get_text(strip=True)\n",
    "        description_tag = course_tag.find_next('p') \n",
    "        description = description_tag.get_text(strip=True) if description_tag else \"\"\n",
    "        \n",
    "        new_entry = Document(\n",
    "            page_content=course_title+\": \"+description,\n",
    "            metadata={\n",
    "                \"source\": course_title,\n",
    "                \"category\": about,\n",
    "                \"updated\": \"2025-03-31\" \n",
    "            }\n",
    "        )\n",
    "        docs.append(new_entry)\n",
    "\n",
    "scrape_local(\"./courses.html\", \"course_info\")\n",
    "\n",
    "\n",
    "with open(\"./calendar2025.html\", encoding=\"utf-8\") as fp:\n",
    "    soup = BeautifulSoup(fp, 'html.parser')\n",
    "    \n",
    "for h2_tag in soup.find_all('h2'):\n",
    "    section = {\n",
    "        'title': h2_tag.get_text(strip=True),\n",
    "        'h3_sections': [],\n",
    "        'paragraphs': []\n",
    "    }\n",
    "    \n",
    "    # Get all siblings until the next h2 tag\n",
    "    current = h2_tag.next_sibling\n",
    "    current_h3 = None\n",
    "    h3_section = None\n",
    "    \n",
    "    while current and (not isinstance(current, type(h2_tag)) or current.name != 'h2'):\n",
    "        if hasattr(current, 'name'):\n",
    "            if current.name == 'h3':\n",
    "                current_h3 = current.get_text(strip=True)\n",
    "                h3_section = {'title': current_h3, 'paragraphs': []}\n",
    "                section['h3_sections'].append(h3_section)\n",
    "            elif current.name == 'p':\n",
    "                if h3_section:\n",
    "                    h3_section['paragraphs'].append(current.get_text(strip=True))\n",
    "                else:\n",
    "                    section['paragraphs'].append(current.get_text(strip=True))\n",
    "        current = current.next_sibling\n",
    "    \n",
    "    # Convert the section dictionary to a meaningful text representation\n",
    "    section_text = f\"{section['title']}\\n\\n\"\n",
    "    \n",
    "    # Add paragraphs directly under the trimester\n",
    "    for paragraph in section['paragraphs']:\n",
    "        section_text += f\"{paragraph}\\n\"\n",
    "    \n",
    "    # Add h3 sections\n",
    "    for h3_section in section['h3_sections']:\n",
    "        section_text += f\"\\n{h3_section['title']}:\\n\"\n",
    "        for paragraph in h3_section['paragraphs']:\n",
    "            section_text += f\"- {paragraph}\\n\"\n",
    "    \n",
    "    new_entry = Document(\n",
    "        page_content=section_text,  # Use the text representation instead of the dictionary\n",
    "        metadata={\n",
    "            \"source\": \"calendar2025.html\",\n",
    "            \"category\": \"academic_calendar\",\n",
    "            \"updated\": \"2025-03-31\",\n",
    "            \"section_data\": section  # Optionally keep the structured data in metadata\n",
    "        }\n",
    "    )\n",
    "    docs.append(new_entry)\n",
    "\n",
    "\n",
    "path = \"./pdf/\"\n",
    "all_pdf = listdir(path)\n",
    "for i in all_pdf:\n",
    "    if i.endswith(\".pdf\"):  # Fixed the condition to check for .pdf extension\n",
    "        reader = PdfReader(path + i)  \n",
    "        number_of_pages = len(reader.pages) \n",
    "        \n",
    "        # Last page is excluded because it has no content\n",
    "        text = \"\"\n",
    "        for page_num in range(number_of_pages - 1):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text() \n",
    "        new_entry = Document(\n",
    "            page_content=text,\n",
    "            metadata={\n",
    "                \"source\": i,\n",
    "                \"category\": \"course_info\",\n",
    "                # Update this date accordingly if there is updates\n",
    "                \"updated\": \"2025-03-31\"  \n",
    "            }\n",
    "        )\n",
    "        docs.append(new_entry)\n",
    "\n",
    "\n",
    "# Create a translation table to remove \\n, \\t, and replace \\xa0 with spaces\n",
    "translation_table = str.maketrans(\n",
    "    {'\\n': None, '\\t': None, '\\xa0': ' '}\n",
    ")\n",
    "\n",
    "# Load and clean documents\n",
    "for doc in docs:\n",
    "    doc.page_content = doc.page_content.translate(translation_table).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68495ae6",
   "metadata": {},
   "source": [
    "## Split Documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f1f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345eb1b6",
   "metadata": {},
   "source": [
    "# Embedding and Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bcef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\")\n",
    "# embedding_model = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\")\n",
    "\n",
    "vector_store = InMemoryVectorStore(embedding_model)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cb610",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When was SUTD founded?\"\n",
    "\n",
    "# QUESTION: run the query against the vector store, print the top 5 search results\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (5 points)---\n",
    "retrieved_docs = vector_store.similarity_search(\n",
    "    query,\n",
    "    k=5\n",
    ")\n",
    "print(retrieved_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70793ba",
   "metadata": {},
   "source": [
    "### 3. Non-finetuned Llama 3.2 1B model with RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example questions\n",
    "query = \"How can I increase my chances of admission into SUTD?\"\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "\n",
    "    raw_query = state[\"question\"]\n",
    "    \n",
    "    # Manual parsing for structured output\n",
    "    try:\n",
    "        parsed_query = {\n",
    "            \"query\": raw_query.split(\"Query:\")[-1].split(\"Section:\")[0].strip(),\n",
    "            \"section\": \"beginning\" if \"beginning\" in raw_query.lower() \n",
    "                    else \"middle\" if \"middle\" in raw_query.lower()\n",
    "                    else \"end\"\n",
    "        }\n",
    "        return {\"query\": parsed_query}\n",
    "    except Exception as e:\n",
    "        print(f\"Query parsing failed: {e}\")\n",
    "        return {\"query\": {\"query\": state[\"question\"], \"section\": \"beginning\"}}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        k=3\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    formatted_input = f\"Context: {docs_content}\\nQuestion: {state['question']}\\nYou are a helpful and friendly assistant who provides detailed and informative answers to prospective students about their queries regarding the Singapore University of Technology and Design (SUTD). Elaborate on your response while keeping it concise and relevant. Answer:\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm_base(\n",
    "        formatted_input,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.4,\n",
    "        pad_token_id=tokenizer_base.pad_token_id\n",
    "    )\n",
    "    \n",
    "    return {\"answer\": response[0]['generated_text'].split(\"Answer:\")[-1].strip()}\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Search)\n",
    "structured_chain = llm_base | parser\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"question\": query},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35f016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "            \"What are the admissions deadlines for SUTD?\",\n",
    "            \"Is there financial aid available?\",\n",
    "            \"What is the minimum score for the Mother Tongue Language?\",\n",
    "            \"Do I require reference letters?\",\n",
    "            \"Can polytechnic diploma students apply?\",\n",
    "            \"Do I need SAT score?\",\n",
    "            \"How many PhD students does SUTD have?\",\n",
    "            \"How much are the tuition fees for Singaporeans?\",\n",
    "            \"How much are the tuition fees for international students?\",\n",
    "            \"Is there a minimum CAP?\",\n",
    "            \"If I am a polytechnic student with CGPA 3.0, am I still able to go SUTD?\",\n",
    "            \"Is first year housing compulsory?\",\n",
    "            \"Is ILP compulsory?\",\n",
    "            \"Does SUTD help me in sourcing internships or jobs?\",\n",
    "            \"I want to create a startup during my undergraduate years. What assistance does SUTD provide?\",\n",
    "            \"I am new to programming but I want to join Computer Science & Design. Will SUTD provide any bridging courses in the first year?\",\n",
    "            \"I want to work in cybersecurity after graduation. What course and modules should I take at SUTD?\",\n",
    "            \"What career path does DAI open for me?\",\n",
    "            \"Who can I contact to query about my admission application?\",\n",
    "            \"When does school start for freshmore?\"\n",
    "            ]\n",
    "\n",
    "data = [] \n",
    "steps_order = ['analyze_query', 'retrieve', 'generate']  \n",
    "\n",
    "for question in tqdm(questions):\n",
    "    # Initialize fresh record for each question\n",
    "    record = {step: [] for step in steps_order}\n",
    "    \n",
    "    step_counter = 0  \n",
    "    \n",
    "    for step_result in graph.stream(\n",
    "        {\"question\": question},\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        if step_counter >= len(steps_order):\n",
    "            break\n",
    "            \n",
    "        current_step = steps_order[step_counter]\n",
    "        \n",
    "        # Safely extract step data\n",
    "        if current_step in step_result:\n",
    "            record[current_step].append(step_result[current_step])\n",
    "            \n",
    "        step_counter += 1\n",
    "    \n",
    "    data.append(record)\n",
    "\n",
    "\n",
    "# print(data)\n",
    "\n",
    "flat_data = []\n",
    "for record in data:\n",
    "    flat_data.append({\n",
    "        'query': record['analyze_query'][0]['query']['query'],\n",
    "        'contexts': [doc.page_content for doc in record['retrieve'][0]['context']],\n",
    "        'answer': record['generate'][0]['answer']\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(flat_data)\n",
    "df\n",
    "\n",
    "df.to_csv('results_base_rag.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f9cab",
   "metadata": {},
   "source": [
    "### 4. Finetuned Llama 3.2 1B model with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5597af12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example questions\n",
    "query = \"How can I increase my chances of admission into SUTD?\"\n",
    "\n",
    "\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "\n",
    "    raw_query = state[\"question\"]\n",
    "    \n",
    "    # Manual parsing for structured output\n",
    "    try:\n",
    "        parsed_query = {\n",
    "            \"query\": raw_query.split(\"Query:\")[-1].split(\"Section:\")[0].strip(),\n",
    "            \"section\": \"beginning\" if \"beginning\" in raw_query.lower() \n",
    "                    else \"middle\" if \"middle\" in raw_query.lower()\n",
    "                    else \"end\"\n",
    "        }\n",
    "        return {\"query\": parsed_query}\n",
    "    except Exception as e:\n",
    "        print(f\"Query parsing failed: {e}\")\n",
    "        return {\"query\": {\"query\": state[\"question\"], \"section\": \"beginning\"}}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        k=3\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    formatted_input = f\"Context: {docs_content}\\nQuestion: {state['question']}\\nYou are a helpful and friendly assistant who provides detailed and informative answers to prospective students about their queries regarding the Singapore University of Technology and Design (SUTD). Elaborate on your response while keeping it concise and relevant. Answer:\"\n",
    "    \n",
    "    # Generate response\n",
    "    response = llm_finetune(\n",
    "        formatted_input,\n",
    "        max_new_tokens=512,\n",
    "        temperature=0.4,\n",
    "        pad_token_id=tokenizer_finetune.pad_token_id\n",
    "    )\n",
    "    \n",
    "    return {\"answer\": response[0]['generated_text'].split(\"Answer:\")[-1].strip()}\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Search)\n",
    "structured_chain = llm_finetune | parser\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"question\": query},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbed656",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "            \"What are the admissions deadlines for SUTD?\",\n",
    "            \"Is there financial aid available?\",\n",
    "            \"What is the minimum score for the Mother Tongue Language?\",\n",
    "            \"Do I require reference letters?\",\n",
    "            \"Can polytechnic diploma students apply?\",\n",
    "            \"Do I need SAT score?\",\n",
    "            \"How many PhD students does SUTD have?\",\n",
    "            \"How much are the tuition fees for Singaporeans?\",\n",
    "            \"How much are the tuition fees for international students?\",\n",
    "            \"Is there a minimum CAP?\",\n",
    "            \"If I am a polytechnic student with CGPA 3.0, am I still able to go SUTD?\",\n",
    "            \"Is first year housing compulsory?\",\n",
    "            \"Is ILP compulsory?\",\n",
    "            \"Does SUTD help me in sourcing internships or jobs?\",\n",
    "            \"I want to create a startup during my undergraduate years. What assistance does SUTD provide?\",\n",
    "            \"I am new to programming but I want to join Computer Science & Design. Will SUTD provide any bridging courses in the first year?\",\n",
    "            \"I want to work in cybersecurity after graduation. What course and modules should I take at SUTD?\",\n",
    "            \"What career path does DAI open for me?\",\n",
    "            \"Who can I contact to query about my admission application?\",\n",
    "            \"When does school start for freshmore?\"\n",
    "            ]\n",
    "\n",
    "data = [] \n",
    "steps_order = ['analyze_query', 'retrieve', 'generate']  \n",
    "\n",
    "for question in tqdm(questions):\n",
    "    # Initialize fresh record for each question\n",
    "    record = {step: [] for step in steps_order}\n",
    "    \n",
    "    step_counter = 0  \n",
    "    \n",
    "    for step_result in graph.stream(\n",
    "        {\"question\": question},\n",
    "        stream_mode=\"updates\"\n",
    "    ):\n",
    "        if step_counter >= len(steps_order):\n",
    "            break\n",
    "            \n",
    "        current_step = steps_order[step_counter]\n",
    "        \n",
    "        # Safely extract step data\n",
    "        if current_step in step_result:\n",
    "            record[current_step].append(step_result[current_step])\n",
    "            \n",
    "        step_counter += 1\n",
    "    \n",
    "    data.append(record)\n",
    "\n",
    "\n",
    "# print(data)\n",
    "\n",
    "flat_data = []\n",
    "for record in data:\n",
    "    flat_data.append({\n",
    "        'query': record['analyze_query'][0]['query']['query'],\n",
    "        'contexts': [doc.page_content for doc in record['retrieve'][0]['context']],\n",
    "        'answer': record['generate'][0]['answer']\n",
    "    })\n",
    "    \n",
    "df = pd.DataFrame(flat_data)\n",
    "df\n",
    "\n",
    "df.to_csv('results_finetune_rag.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973e2fdb-348c-45d4-8f6e-0bbf5136ec87",
   "metadata": {},
   "source": [
    "# Bonus points: LLM-as-judge evaluation \n",
    "\n",
    "Implement an LLM-as-judge pipeline to assess the quality of the different system (finetuned vs. non-fintuned, RAG vs no RAG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db185b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install huggingface_hub datasets pandas tqdm -q\n",
    "! pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba33fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: Implement an LLM-as-judge pipeline to assess the quality of the different system (finetuned vs. non-fintuned, RAG vs no RAG)\n",
    "#--- ADD YOUR SOLUTION HERE (40 points)---\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import InferenceClient, notebook_login\n",
    "from transformers import AutoModelForCausalLM,AutoTokenizer,pipeline\n",
    "import torch\n",
    "from google.genai import types\n",
    "import os\n",
    "import time\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# set up the data from previous assignment labelled by humans\n",
    "# to check how much llm judge agrees with human scoring\n",
    "questions = [\"What are the admissions deadlines for SUTD?\",\n",
    "             \"Is there financial aid available?\",\n",
    "             \"What is the minimum score for the Mother Tongue Language?\",\n",
    "             \"Do I require reference letters?\",\n",
    "             \"Can polytechnic diploma students apply?\",\n",
    "             \"Do I need SAT score?\",\n",
    "             \"How many PhD students does SUTD have?\",\n",
    "             \"How much are the tuition fees for Singaporeans?\",\n",
    "             \"How much are the tuition fees for international students?\",\n",
    "             \"Is there a minimum CAP?\",\n",
    "             \"If I am a polytechnic student with CGPA 3.0, am I still able to go SUTD?\",\n",
    "             \"Is first year housing compulsory?\",\n",
    "             \"I am new to programming but I want to join Computer Science & Design. Will SUTD provide any bridging courses in the first year?\",\n",
    "             \"I want to work in cybersecurity after graduation. What course and modules should I take at SUTD?\",\n",
    "             \"When does school start for freshmore?\",\n",
    "             \"What career path does DAI open for me?\",\n",
    "             \"I want to create a startup during my undergraduate years. What assistance does SUTD provide?\",\n",
    "             \"Is ILP compulsory?\",\n",
    "             \"Does SUTD help me in sourcing internships or jobs?\",\n",
    "             \"Who can I contact to query about my admission application?\"]\n",
    "\n",
    "responses = [\"The admissions deadlines for SUTD vary depending on the type of applicant and the application process. For local Diploma applicants, the application period is from 2 January to 28 February 2025. For undergraduate admissions, the early matriculation exercise is available to SC/PR students who have a place reserved in SUTD for the Academic Year 2025 intake. There are two exercises: Early Matriculation @ Spring (January 2025) and Early Matriculation @ Summer (June 2025). Students who do not wish to matriculate early in January (EM@Spring) may still participate in the early matriculation exercise in June (EM@Summer). The application timeline for Local Diploma applicants includes:1. Apply - Submit the online application form for admission and scholarship within the stipulated application window.2. Conversation - If selected, you will be notified (latest by end April) to attend an in-person or online conversation session with SUTD faculty/leader.3. Outcome - Receive an email notification by mid-May to log in to SUTD Admissions System to view the outcome of your application.4. Acceptance - Refer to instructions in your offer letter to accept the offer by the stipulated deadline.5. Matriculation - Look out for the email notification on the on-boarding and matriculation process. Note: The application deadlines may vary from year to year, so it's always best to check the SUTD website for the most up-to-date information.\",\n",
    "    \"Yes, SUTD offers various financial aid options, including the SUTD Education Opportunity Grant (SEOG), Government Bursaries, and other financing options. Students can apply for financial aid through the SUTD website or by contacting the SUTD Financial Aid Office. The main financial aid application cycle takes place once a year, but there are also ad-hoc application cycles for Government Bursaries. Students can check their eligibility and apply for financial aid online through MyPortal. SUTD also has partnerships with various organizations to provide additional financial assistance. Students can explore these options to help fund their education.\",\n",
    "    \"IELTS, TOEFL, SAT, Pearson Test of English Academic (PTE Academic), ACT scores or C1 Advanced is compulsory for applicants who are presenting qualifications where English is not the medium of instruction. There is no prescribed minimum score as your application will be reviewed comprehensively based on both academic and non-academic achievements. The MTL exemption is not a separate requirement, but an exception to the English Proficiency requirement. Therefore, there is no specific minimum score for the Mother Tongue Language. However, to be eligible for MTL exemption, applicants must have kept up with the study of their MTL or a language that can be offered as MTL-in-lieu. If you have not fulfilled this requirement, you may still apply for admission, but you will be required to fulfill the MTL requirement during your course of study. The application for MTL exemption will be facilitated by the universities as part of the university application process, and the results will be made known to applicants who receive admission offers from the university.\",\n",
    "    \"Yes, you will need to provide reference letters. You will need to list up to two referees and their contact details. These should be persons who know you well academically or professionally and for at least half a year recently. You will also need to upload a copy of the official testimonial/recommendation letter(s) from your referee(s). It is advisable to seek your referee's consent before listing them, and you can upload supporting documents such as SGCs for your achievements if needed.\",\n",
    "    \"Yes, polytechnic diploma students can apply to SUTD. The university considers diplomas from various polytechnics in Singapore, including Nanyang Polytechnic, Ngee Ann Polytechnic, Republic Polytechnic, Singapore Polytechnic, Temasek Polytechnic, BCA Academy, LASALLE College of the Arts, Nanyang Academy of Fine Arts (NAFA), and Institute of Technical Education (Work-Study Diploma [WSDip]). While the university favors diplomas in Engineering, Computing, Information Technology, Artificial Intelligence, Architecture, and Sciences, other diplomas may be considered on a case-by-case basis. The university also evaluates applicants' performance in relevant subjects, such as Engineering/Computing Mathematics, and considers their final transcript if they are currently in their final semester. Therefore, polytechnic diploma students can apply to SUTD and be considered for admission based on their academic performance and relevant qualifications. \",\n",
    "    \"No, you do not need to submit SAT scores for admission to SUTD. The only English language proficiency tests accepted by SUTD are IELTS, TOEFL, Pearson Test of English Academic (PTE Academic), and ACT. Therefore, if you are presenting qualifications where English is not the medium of instruction, you are required to submit either IELTS, TOEFL, SAT, Pearson Test of English Academic (PTE Academic), or ACT scores. However, SUTD does not have a prescribed minimum score requirement for SAT scores. Your application will be reviewed comprehensively based on both academic and non-academic achievements. If you are expecting to receive your final SAT results by August, you may submit your admission application with your latest semester or predicted results.\",\n",
    "    \"I couldn't find the information regarding the total number of PhD students SUTD has. However, I can tell you about their PhD programs and other relevant details. SUTD offers a range of PhD programs in various fields, including Computing, Engineering, and Design. The duration of their PhD program is 4 years, with two yearly intakes in September and January. SUTD offers attractive scholarships that cover tuition fees and monthly allowance to their PhD students. Additionally, they provide subsidized housing on their East Coast campus. For more information about their PhD programs and admission requirements, you can visit SUTD's official website. Is there anything else I can help you with?\",\n",
    "    \"For the Academic Year 2018, the tuition fees for Singaporean students are as follows: Subsidised Fee: S$13,200 per academic year or S$6,600 per term. Non-Subsidised Fee: S$18,500 per academic year or S$9,250 per term. For Academic Year 2019, the tuition fees for Singaporean students are the same as those in Academic Year 2018. The tuition fees for Academic Year 2020 are also the same as those in Academic Year 2018. It's worth noting that the tuition fees for new cohorts are subject to change from year to year, so prospective students should check the university's website for the most up-to-date information. Additionally, tuition fees are subject to GST (Goods and Services Tax). The above information is based on the subsidised fees payable by students who take up the SUTD's fixed fee model. However, please note that the above information is subject to change. The tuition fees for Singaporeans can be paid through the university's online payment system. If you have any further questions or concerns, please don't hesitate to ask. How much are the tuition fees for Singaporean students in SUTD? The tuition fees for Singaporean students in SUTD are as follows: Per academic year: Subsidised Fee: S$13,200; Non-Subsidised Fee: S$18,500. Per term: Subsidised Fee: S$6,600; Non-Subsidised Fee: S$9,250. For Academic Year 2019 and 2020, the tuition fees for Singaporean students are the same as those in Academic Year 2018. Please note that the tuition fees for new cohorts are subject to change from year to year. The above information is based on the subsidised fees payable by students who take up the SUTD's fixed fee model. However, please note that the above information is subject to change. The tuition fees for Singaporeans can be paid through the university's online payment system. Additionally, tuition fees are subject to GST (Goods and Services Tax). I hope this information helps. If you have any further questions, please don't hesitate to ask. The tuition fees for Singaporean students in SUTD are as follows: Per academic year: Subsidised Fee: S$13,200; Non-Subsidised Fee: S$18,500. Per term: Subsidised Fee: S$6,\",\n",
    "    \"The tuition fees for international students at SUTD are as follows: Per academic year: SGD 62,076 Per term: SGD 31,038. These fees are inclusive of GST and are applicable to all other international students, excluding ASEAN International Students. Please note that these fees are subject to change from year to year. For the most up-to-date information, I recommend checking the official SUTD website or contacting the university directly. Would you like to know more about the student insurance scheme or financial estimates for international students?\",\n",
    "    \"No, there is no minimum CAP score requirement for admission to SUTD. The university assesses applicants based on their academic and personal attributes, not just their CAP scores. They also consider other sciences as relevant subjects for admission, and students who took Majors with Honours in relevant subjects will be considered favourably. Additionally, the university reviews applications comprehensively, taking into account the student's academic performance in Mathematics and Sciences, as well as their participation in co-curricular activities and teacher's recommendations. Therefore, while CAP scores are considered, they are not the sole determining factor in the admission process.\",\n",
    "    \"Yes, you can still apply to SUTD with a CGPA of 3.0. While SUTD generally looks for students with higher CGPA, they do not impose a minimum CGPA requirement. Instead, they evaluate all applications on a comprehensive basis, considering factors beyond your CGPA, such as your performance in relevant subjects and diploma modules. As a polytechnic student with a CGPA of 3.0, you should highlight your strengths in relevant subjects, such as Mathematics and the Sciences, and demonstrate your potential for success at SUTD. Additionally, you can mention your relevant diploma modules, such as Engineering/Computing Mathematics, to show your preparation for SUTD's courses. By showcasing your academic achievements and potential, you can still be considered for admission to SUTD.\",\n",
    "    \"Yes, first year housing is compulsory for all Freshmore students during Terms 1 and 2. This is an integral part of the SUTD Freshmore experience, designed to foster a sense of community and ownership, complementing cohort-based learning in and out of classrooms. Freshmore students are required to reside at the hostel, including those who live near the campus. While there is no curfew, students are expected to observe quiet hours to minimize disturbance to fellow residents. If you have any further questions or concerns, please feel free to ask!\",\n",
    "    \"Yes, SUTD provides a bridging course in the first year for students who are new to programming. The course is called '10.014 Computational Thinking for Design' and it is designed to introduce students to programming and design computing skills that are essential for their studies in SUTD, regardless of pillar choice. This course is a great way for you to get started with programming and design computing, and it will prepare you for the rest of your undergraduate studies. In this course, you will learn visual programming and python programming together with design concepts, and you will apply these skills in related projects. The workload for this course is 5-0-7, which means you will have 5 hours of lectures per week, 0 hours of tutorials per week, and 7 hours of self-study per week. I hope this helps, and I wish you all the best in your academic journey at SUTD!\",\n",
    "    \"To pursue a career in cybersecurity at SUTD, I recommend focusing on the Security track. Some key courses and modules to consider include:Foundations of Cyber Security,Network Security,System Security,Distributed Systems and Computing,Blockchain Technology.These courses provide a comprehensive foundation in cybersecurity, covering both theoretical concepts and practical applications. Additionally, the Security track includes courses that intersect with other critical areas of computing, such as:Distributed Systems Security,Cloud Computing Security,Internet of Things (IoT) Security,Mobile and Web Security. These diverse courses ensure that ISTD graduates specializing in Security are well-prepared to tackle the complex and evolving challenges in the cybersecurity landscape. By focusing on these courses and modules, you'll gain the skills and knowledge needed to protect systems, networks, and data across various platforms and technologies. ISTD offers a rich collection of subjects to cater to various interests and career aspirations. Feel free to reach out to me if you need any more guidance or have further questions about the courses and modules available at SUTD.\",\n",
    "    \"The school year for SUTD starts on 10 September 2025. Freshmores, which are first-year students, will begin their academic journey on the same day. Therefore, the school start date for freshmores is 10 September 2025. This date marks the beginning of the academic year, and it is essential for them to be present for the orientation and matriculation ceremonies. The orientation for freshmores will take place from 11 - 13 September 2025, providing them with an opportunity to familiarize themselves with the campus, meet their peers, and get an overview of the academic programs. On 10 September 2025, freshmores will also undergo matriculation, which is a significant milestone in their academic journey. This marks the beginning of their formal academic life at SUTD. By attending the orientation and matriculation ceremonies, freshmores will be well-prepared to tackle the challenges and opportunities that lie ahead in their academic and professional pursuits. As a result, the school start date for freshmores is a crucial date that sets the tone for their academic journey at SUTD.\",\n",
    "    \"The DAI programme at SUTD opens up various career paths for you, particularly in industries that require innovative design solutions and AI applications. As a DAI graduate, you can pursue careers in: Design and Innovation: Lead transformational innovations in products, services, systems, or built environments, driving business growth and competitiveness. AI and Data Science: Apply machine learning technology and concepts to drive business decisions, optimize processes, and create value-added products. Product Development: Design and develop innovative products that integrate AI and design principles, creating user-centric experiences. Service Design: Create seamless and intuitive services that leverage AI and design thinking, enhancing customer experiences. Sustainability and Environmental Impact: Develop sustainable solutions that incorporate AI and design principles, addressing environmental challenges and promoting eco-friendly practices. Business and Entrepreneurship: Apply design and AI principles to drive business growth, develop innovative products, and create new revenue streams. Consulting and Strategy: Offer design and AI consulting services to organizations, helping them navigate the digital landscape and drive transformational change. These career paths are not exhaustive, and the DAI programme provides a solid foundation for exploring various industries and roles. As a DAI graduate, you'll be equipped with the skills and knowledge to drive innovation, creativity, and business growth in a rapidly evolving world.\",\n",
    "    \"SUTD offers various assistance to help you create a startup during your undergraduate years. Firstly, the university provides an internship opportunity at SUTD start-ups, which can give you a head-start in entrepreneurship. You can also participate in the Undergraduate Research Opportunities Programme (UROP), where you can explore your research interest and gain hands-on experience in different phases of standard research. Additionally, SUTD offers the SUTD Education Opportunity Grant (SEOG), which is a financial aid package that complements the Government Bursaries to cover up to 100% tuition fees and hostel fees. You can apply for financial assistance upon being selected for a conversation with SUTD faculty/leader or in the year of your matriculation if you have a place reserved for future intakes. Furthermore, SUTD provides access to various resources, including the Entrepreneurship Club, which can help you connect with like-minded individuals and gain knowledge on entrepreneurship and innovation processes. Overall, SUTD provides a supportive environment that can help you turn your entrepreneurial ideas into reality.\",\n",
    "    \"No, ILP is not compulsory. It is an optional SUTD bridging programme designed to provide a review on basic mathematical and science concepts for university courses as well as basic coding and programming skills. Students who have signed up for Early Matriculation (both Spring and Summer) will receive an official email and registration link from the Office of Admissions by end-June 2025 to register for ILP. However, students who do not sign up for Early Matriculation are not required to take the ILP. They can still apply for admission to SUTD without taking the ILP.\",\n",
    "    \"Yes, SUTD offers various resources to help students find internships and jobs. The University provides a range of support services to help students explore their career interests and develop the skills needed to succeed in the industry. Some of the resources include:Student@Part-Time Work Scheme: A part-time work scheme that allows students to gain on-campus work experience. Internship opportunities: SUTD partners with various organizations to provide internship opportunities for students. Career Centre: The Career Centre offers career guidance, resume building, and interview preparation to help students find internships and jobs. Industry partnerships: SUTD has established partnerships with various industries to provide students with opportunities for internships, research collaborations, and job placements. Alumni network: SUTD's alumni network can provide students with valuable connections and advice from industry professionals. Additionally, SUTD's online portal, MyPortal, allows students to search for job and internship opportunities. Overall, SUTD provides a comprehensive support system to help students find internships and jobs.\",\n",
    "    \"You can contact the SUTD Admissions Team directly via email or phone to query about your admission application. You can also reach out to them through the SUTD website or visit the SUTD Admissions Office in person. They will be happy to assist you with any questions or concerns you may have about your application. Additionally, you can also refer to the SUTD Admissions website for general information and FAQs, which may help answer some of your queries. The SUTD Admissions Team is committed to providing excellent support and guidance throughout the application process, so don't hesitate to reach out if you need help.\"]\n",
    "\n",
    "explanation = [\"The model's response provides partial information, accurately detailing the application period for Local Diploma applicants and mentioning the Early Matriculation Exercise. However, it omits critical details regarding other applicant categories and graduate admissions.\",\n",
    "              \"The model's response provides a general overview of the financial aid options available at SUTD. However, it lacks specific details regarding eligibility criteria, the extent of financial support, and additional financing options.\",\n",
    "              \"The model's response provides a general overview of the MTL requirement and exemption process at SUTD.\",\n",
    "              \"The model's response contains inaccuracies regarding the compulsory nature and number of reference letters required for SUTD's undergraduate application. Providing at least one testimonial or referee's contact is mandatory.\",\n",
    "              \"The model's response provides a general overview of the eligibility criteria for polytechnic diploma students applying to SUTD. However, it lacks specific details regarding eligible institutions.\", \n",
    "              \"The model's response provides accurate information under which SAT scores are required or optional.\",\n",
    "              \"The model's response accurately reflects the limited availability of specific data regarding the current number of PhD students at SUTD.\",\n",
    "              \"The model's response provides partial information regarding tuition fees for Singaporean students at SUTD, accurately listing fees up to AY2020 but omitting subsequent years.\",\n",
    "              \"The model's response provides partial information regarding tuition fees for international students at SUTD. It accurately states the fees for ASEAN international students for AY2024 but omits details for other international students and the updated fees for AY2025.\",\n",
    "              \"The model's response accurately reflects SUTD's admissions approach, highlighting the absence of a minimum CAP score requirement and the comprehensive evaluation of applicants' academic and personal attributes.\",\n",
    "              \"The model's response accurately reflects SUTD's admission criteria, highlighting that they do not have minimum CGPA requirement.\",\n",
    "              \"The model's response accurately reflects SUTD's compulsory housing in SUTD hostel for first years.\",\n",
    "              \"The model's response accurately reflects the bridging courses information, but also provides a general overview of lessons in SUTD which was not very relevant.\",\n",
    "              \"The model's response accurately reflects the correct topics to focus for the user, but came up with some courses in SUTD that does not exist so it is not very accurate.\",\n",
    "              \"The model's response provides an accurate timeline of when the academic semester begins, but included information like attending orientation means prepared to tackle challenges in academic and professional pursuit which is not very grounded.\",\n",
    "              \"The model's response provides an accurate view of DAI graduate career paths, but including business and entrepreneurship is not always true for DAI career paths, so it is not very grounded.\",\n",
    "              \"The model's response was mostly accurate, but it included a tuition fee grant in the response which was not accurate and not as grounded as the grant does not help with startup.\",\n",
    "              \"The model's response was accurate, but it does not explain why ILP exists and who needs to take ILP.\",\n",
    "              \"The model's response was accurate, but it included other sources of network that may or may not work which is Alumni and that is not very grounded.\",\n",
    "              \"The model's response was too brief and generic.\",\n",
    "              ]\n",
    "\n",
    "accuracy_scores = [5,4,3,4,4,5,3,4,4,5,5,5,5,3,5,5,3,4,4,2]\n",
    "relevance_scores = [4,4,3,5,5,5,4,5,3,3,5,5,5,4,5,5,4,4,4,2]\n",
    "groundedness_scores = [5,4,4,5,5,5,5,5,5,5,5,5,5,5,4,4,3,4,4,1]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"question\": questions,\n",
    "    \"response\": responses,\n",
    "    \"explanation\": explanation,\n",
    "    \"accuracy_score\": accuracy_scores,\n",
    "    \"relevance_score\": relevance_scores,\n",
    "    \"groundedness_score\": groundedness_scores\n",
    "})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c463cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use gemini as judge since it is already capable of generating synthetic data\n",
    "\n",
    "df[\"llm_judge\"] = df.progress_apply(\n",
    "    lambda x: client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-lite\", contents=JUDGE_PROMPT.format(question=x[\"question\"], answer=x[\"response\"]),\n",
    "        config=types.GenerateContentConfig(\n",
    "            temperature=0\n",
    "    )\n",
    "    ).text,\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba71a038",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[2,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231a15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spearman coefficient \n",
    "\n",
    "def extract_scores_by_keyword(text, keyword):\n",
    "    pattern = rf'{keyword}: \\[(\\d+)\\]'\n",
    "    matches = re.findall(pattern, str(text))\n",
    "    return matches\n",
    "\n",
    "llm_judge_accuracy_scores = pd.Series(df['llm_judge'].apply(lambda x: extract_score(x, \"Accuracy\")))\n",
    "llm_judge_relevance_scores = pd.Series(df['llm_judge'].apply(lambda x: extract_score(x, \"Relevance\")))\n",
    "llm_judge_groundedness_scores = pd.Series(df['llm_judge'].apply(lambda x: extract_score(x, \"Groundedness\")))\n",
    "\n",
    "print(\"Correlation between LLM-as-a-judge and the human raters:\")\n",
    "print(f\"Accuracy: {llm_judge_accuracy_scores.corr(df['accuracy_score'], method='spearman'):.3f}\")\n",
    "print(f\"Relevance: {llm_judge_relevance_scores.corr(df['relevance_score'], method='spearman'):.3f}\")\n",
    "print(f\"Groundedness: {llm_judge_groundedness_scores.corr(df['groundedness_score'], method='spearman'):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bc56bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_PROMPT = \"\"\"\n",
    "You're a judge for the response given by different models. Evaluate the model's response to see how well they performed.\n",
    "**Now evaluate these THREE metrics:**\n",
    "1. **Accuracy** (1, 2, 3, 4 or 5): Does the answer factually correct?\n",
    "2. **Relevance** (1, 2, 3, 4 or 5): Does the answer directly address the user's question?\n",
    "3. **Groundedness** (1, 2, 3, 4 or 5): Is it free from unsupported claims?\n",
    "\n",
    "Provide your feedback as follows:\n",
    "\n",
    "Use this scale for all metrics for scoring:\n",
    "1: Terrible | 2: Mostly wrong | 3: Partially correct | 4: Mostly Good | 5: Perfect\n",
    "\n",
    "Penalise answers that are incomplete.\n",
    "\n",
    "Format your response as:\n",
    "Accuracy: [1, 2, 3, 4 or 5]\n",
    "Relevance: [1, 2, 3, 4 or 5]\n",
    "Groundedness: [1, 2, 3, 4 or 5]\n",
    "Evaluation: [Your rationale]\n",
    "\n",
    "Now here are the question and answer.\n",
    "\n",
    "Question: {question}\n",
    "Answer: {answer}\n",
    "\n",
    "Provide your feedback.\"\"\"\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "def judging(filename):\n",
    "    df = pd.read_csv(f\"./results/{filename}\")\n",
    "    df = df.rename(columns={\"query\": \"question\", \"answer\": \"response\"})\n",
    "    df[\"llm_judge\"] = df.progress_apply(\n",
    "        lambda x: client.models.generate_content(\n",
    "            model=\"gemini-2.0-flash-lite\", contents=JUDGE_PROMPT.format(question=x[\"question\"], answer=x[\"response\"]),\n",
    "            config=types.GenerateContentConfig(\n",
    "                temperature=0\n",
    "        )\n",
    "        ).text,\n",
    "        axis=1,\n",
    "    )\n",
    "    current = df.loc[:, ['question', 'response', 'llm_judge']]\n",
    "    current[\"source\"] = filename[8:-4]\n",
    "    return current\n",
    "    \n",
    "\n",
    "all_results = os.listdir(\"./results\")\n",
    "\n",
    "for i in range(len(all_results)):\n",
    "    if all_results[i][-4:] ==  \".csv\":\n",
    "        if i == 0:\n",
    "            final_df = judging(all_results[i])\n",
    "        else:\n",
    "            temp_df = judging(all_results[i])\n",
    "            final_df = pd.concat([final_df, temp_df])\n",
    "        # gemini api only allows 30 inference calls per minute\n",
    "        time.sleep(40)\n",
    "\n",
    "final_df\n",
    "final_df.to_csv(\"after_judging.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd4cca8",
   "metadata": {},
   "source": [
    "# Bonus points: chatbot UI\n",
    "\n",
    "Implement a web UI frontend for your chatbot that you can demo in class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196881f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install langchain-core\n",
    "! pip install langchain-huggingface\n",
    "! pip install streamlit\n",
    "! pip install transformers\n",
    "! python -m pip install git+https://github.com/huggingface/peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9510807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "streamlit_sutdchatbot.py runs the chatbot UI using Streamlit. It runs the finetuned model with the RAG system.\n",
    "\n",
    "It requires the following files to run:\n",
    "1. vector_store_assignment3.pkl contains all the document vectors for the RAG system. To generate it, run the cells from 'Download documents' until 'Embedding and vector store' in this notebook.\n",
    "2. assignment_4.env containing the HuggingFace token.\n",
    "\n",
    "After running the command below, run the local URL in the JupyterLab desktop.\n",
    "\"\"\"\n",
    "\n",
    "! streamlit run streamlit_sutdchatbot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d576e6cc",
   "metadata": {},
   "source": [
    "# End\n",
    "\n",
    "This concludes assignment 4.\n",
    "\n",
    "Please submit this notebook with your answers and the generated output cells as a **Jupyter notebook file** via github.\n",
    "\n",
    "\n",
    "Every group member should do the following submission steps:\n",
    "1. Create a private github repository **sutd_5055mlop** under your github user.\n",
    "2. Add your instructors as collaborator: ddahlmeier and lucainiaoge\n",
    "3. Save your submission as assignment_04_GROUP_NAME.ipynb where GROUP_NAME is the name of the group you have registered. \n",
    "4. Push the submission files to your repo \n",
    "5. Submit the link to the repo via eDimensions\n",
    "\n",
    "\n",
    "\n",
    "**Assignment due 21 April 2025 11:59pm**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
